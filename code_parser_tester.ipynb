{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50884d42",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6687368",
   "metadata": {},
   "outputs": [],
   "source": [
    "Function_Path = \"Inventory.views_pack.terminal.saudi_tsr_output_checker\" # Inventory.views_pack.terminal.process_exe_data\n",
    "BASE_PATH = r\"C:\\Users\\JonathanChackoPattas\\OneDrive - Maritime Support Solutions\\Desktop\\MSS-Automation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e7a7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from typing import Optional, Dict, Tuple, List, Union, Iterable, Set, Any\n",
    "# from google.adk.tools.tool_context import ToolContext\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "# -----------------------------\n",
    "# project indexing\n",
    "# -----------------------------\n",
    "\n",
    "_EXCLUDE_DIRS = {\n",
    "    \".git\", \"__pycache__\", \".mypy_cache\", \".pytest_cache\", \".ruff_cache\",\n",
    "    \"build\", \"dist\", \"site-packages\", \"venv\", \".venv\", \"env\", \".env\",\n",
    "    \".idea\", \".vscode\", \"node_modules\", \".tox\", \".eggs\",\n",
    "    \"venv-windows\", \"venv-linux\",\n",
    "}\n",
    "\n",
    "def create_file_path(base_path, function_path):\n",
    "    function_parts = function_path.split(\".\")\n",
    "    function_name = function_parts[-1]  # last part is the function\n",
    "    module_parts = function_parts[:-1]  # everything before is the module path\n",
    "    for part in module_parts:\n",
    "        base_path = os.path.join(base_path, part)\n",
    "    return base_path + \".py\", function_name\n",
    "\n",
    "def _iter_py_files(root: Path) -> Iterable[Path]:\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        # prune excluded dirs in-place for speed\n",
    "        dirnames[:] = [d for d in dirnames if d not in _EXCLUDE_DIRS]\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".py\"):\n",
    "                yield Path(dirpath) / f\n",
    "\n",
    "def _to_module_qualname(base_path: Path, file_path: Path) -> str:\n",
    "    rel = file_path.relative_to(base_path)\n",
    "    if rel.name == \"__init__.py\":\n",
    "        rel = rel.parent\n",
    "    else:\n",
    "        rel = rel.with_suffix(\"\")\n",
    "    return \".\".join(rel.parts)\n",
    "\n",
    "def _to_function_path(base_path: Path, file_path: Path, func_name: str) -> str:\n",
    "    mod = _to_module_qualname(base_path, file_path)\n",
    "    return f\"{mod}.{func_name}\" if mod else func_name\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "@lru_cache(maxsize=4)\n",
    "def _index_project_functions(base_path_str: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        by_name: Dict[str, List[tuple[Path, str /*module*/, FuncNode]]]\n",
    "        by_mod_func: Dict[str /*module.func*/, tuple[Path, FuncNode]]\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path_str).resolve()\n",
    "    by_name: Dict[str, List[Tuple[Path, str, FuncNode]]] = {}\n",
    "    by_mod_func: Dict[str, Tuple[Path, FuncNode]] = {}\n",
    "\n",
    "    for py in _iter_py_files(base_path):\n",
    "        try:\n",
    "            src = py.read_text(encoding=\"utf-8\")\n",
    "            mod = ast.parse(src)\n",
    "        except Exception:\n",
    "            continue  # skip unreadable / syntactically invalid files\n",
    "\n",
    "        top_funcs, _ = _gather_defs(mod)\n",
    "        module_name = _to_module_qualname(base_path, py)\n",
    "        for name, node in top_funcs.items():\n",
    "            by_name.setdefault(name, []).append((py, module_name, node))\n",
    "            by_mod_func[f\"{module_name}.{name}\"] = (py, node)\n",
    "\n",
    "    return by_name, by_mod_func\n",
    "\n",
    "# -----------------------------\n",
    "# source slicing & calls\n",
    "# -----------------------------\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "def _get_attr_chain(node: ast.AST) -> Tuple[Optional[str], List[str]]:\n",
    "    \"\"\"\n",
    "    For something like pkg.sub.mod.helper, return (\"pkg\", [\"sub\", \"mod\", \"helper\"]).\n",
    "    If not an attribute chain rooted at Name, return (None, []).\n",
    "    \"\"\"\n",
    "    chain: List[str] = []\n",
    "    cur = node\n",
    "    root_name = None\n",
    "    while isinstance(cur, ast.Attribute):\n",
    "        chain.append(cur.attr)\n",
    "        cur = cur.value\n",
    "    if isinstance(cur, ast.Name):\n",
    "        root_name = cur.id\n",
    "        chain.reverse()\n",
    "        return root_name, chain\n",
    "    return None, []\n",
    "\n",
    "def _collect_calls_and_locals(fn: FuncNode) -> tuple[set[str], list[tuple[str, list[str]]], set[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      bare: names of bare calls like {'helper', 'slugify'}\n",
    "      attrs: qualified calls like [('utils', ['slugify']), ('pkg', ['sub', 'do'])]\n",
    "      bound_locals: names bound in the function (params, assignments, etc.)\n",
    "    \"\"\"\n",
    "    bare: Set[str] = set()\n",
    "    attrs: List[Tuple[str, List[str]]] = []\n",
    "    bound_locals: Set[str] = set()\n",
    "\n",
    "    # params\n",
    "    args = fn.args\n",
    "    for a in getattr(args, \"posonlyargs\", []): bound_locals.add(a.arg)\n",
    "    for a in args.args: bound_locals.add(a.arg)\n",
    "    if args.vararg: bound_locals.add(args.vararg.arg)\n",
    "    for a in args.kwonlyargs: bound_locals.add(a.arg)\n",
    "    if args.kwarg: bound_locals.add(args.kwarg.arg)\n",
    "\n",
    "    def add_targets(t):\n",
    "        if isinstance(t, ast.Name):\n",
    "            bound_locals.add(t.id)\n",
    "        elif isinstance(t, (ast.Tuple, ast.List)):\n",
    "            for elt in t.elts:\n",
    "                add_targets(elt)\n",
    "\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call):\n",
    "            if isinstance(n.func, ast.Name):\n",
    "                bare.add(n.func.id)\n",
    "            else:\n",
    "                root, chain = _get_attr_chain(n.func)\n",
    "                if root and chain:\n",
    "                    attrs.append((root, chain))\n",
    "        elif isinstance(n, ast.Assign):\n",
    "            for t in n.targets: add_targets(t)\n",
    "        elif isinstance(n, ast.AnnAssign) and n.target:\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.AugAssign):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.For):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.With):\n",
    "            for item in n.items:\n",
    "                if item.optional_vars: add_targets(item.optional_vars)\n",
    "        elif isinstance(n, ast.comprehension):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.ExceptHandler) and n.name:\n",
    "            bound_locals.add(n.name)\n",
    "\n",
    "    return bare, attrs, bound_locals\n",
    "\n",
    "# -----------------------------\n",
    "# import resolution\n",
    "# -----------------------------\n",
    "\n",
    "def _resolve_relative_module(this_module: str, level: int, module: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Resolve relative 'from ... import ...' to absolute dotted module.\n",
    "    this_module: e.g., 'Inventory.views_pack.terminal'\n",
    "    level: 1 => from . import x  (parent)\n",
    "    level: 2 => from ..pkg import y\n",
    "    \"\"\"\n",
    "    pkg_parts = this_module.split(\".\")[:-1]  # package of the file\n",
    "    if level > len(pkg_parts) + 1:\n",
    "        return None\n",
    "    base = pkg_parts[: len(pkg_parts) - (level - 1)]\n",
    "    if module:\n",
    "        base += module.split(\".\")\n",
    "    return \".\".join(p for p in base if p)\n",
    "\n",
    "def _parse_import_maps(mod: ast.Module, this_module: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      import_aliases: dict of local name -> absolute module dotted path\n",
    "         e.g., {'utils': 'Inventory.utils', 'mod': 'Inventory.x.y'}\n",
    "      from_names: dict of local imported symbol -> absolute module or module.symbol\n",
    "         e.g., {'slugify': 'Inventory.utils.slugify', 'utils': 'Inventory.utils'}\n",
    "    \"\"\"\n",
    "    import_aliases: Dict[str, str] = {}\n",
    "    from_names: Dict[str, str] = {}\n",
    "\n",
    "    for n in mod.body:\n",
    "        if isinstance(n, ast.Import):\n",
    "            for a in n.names:\n",
    "                full = a.name  # 'pkg' or 'pkg.sub.mod'\n",
    "                local = a.asname if a.asname else full.split(\".\")[0]\n",
    "                import_aliases[local] = full\n",
    "        elif isinstance(n, ast.ImportFrom):\n",
    "            if n.level and n.level > 0:\n",
    "                base_mod = _resolve_relative_module(this_module, n.level, n.module)\n",
    "            else:\n",
    "                base_mod = n.module\n",
    "            if not base_mod:\n",
    "                continue\n",
    "            for a in n.names:\n",
    "                local = a.asname if a.asname else a.name\n",
    "                # Could be a submodule or a symbol; we store as fully qualified\n",
    "                from_names[local] = f\"{base_mod}.{a.name}\"\n",
    "    return import_aliases, from_names\n",
    "\n",
    "# -----------------------------\n",
    "# main API\n",
    "# -----------------------------\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    "    *,\n",
    "    base_path: str | Path,\n",
    "    detailed_functions: bool = False,\n",
    "    recursive_helper: bool = False,\n",
    "    aggressive_fallback: bool = False,  # set True to allow cross-project name fallback\n",
    "    # tool_context: ToolContext\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "\n",
    "    Args:\n",
    "      file_path: Path to the file containing the target function/method.\n",
    "      func_or_qualname: \"foo\" or \"ClassName.method\".\n",
    "      include_helpers: If True, also return helper function *paths* discovered\n",
    "                       from calls inside the target, searching across the project.\n",
    "      base_path: Project root directory. Only files under this root are considered.\n",
    "      detailed_functions: If True, include detailed information about function arguments and return types.\n",
    "      recursive_helper: If True, include helper functions found in the same file.\n",
    "      aggressive_fallback: If True, when we can't prove a binding, include all\n",
    "                           same-named top-level functions found across the project.\n",
    "      tool_context: Tool context (optional for session actions).\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        \"code\": str,\n",
    "        \"start_line\": int,\n",
    "        \"end_line\": int,\n",
    "        \"function\": str,\n",
    "        \"file\": str,\n",
    "        \"helpers\": List[str]  # dotted function paths across the project\n",
    "      }\n",
    "    \"\"\"\n",
    "    base = Path(base_path).resolve()\n",
    "    path = Path(file_path).resolve()\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "\n",
    "    helper_function_paths: List[str] = []\n",
    "    helper_function_paths_final = []\n",
    "    if include_helpers:\n",
    "        by_name, by_mod_func = _index_project_functions(str(base))\n",
    "\n",
    "        this_module = _to_module_qualname(base, path)\n",
    "        import_aliases, from_names = _parse_import_maps(mod, this_module)\n",
    "\n",
    "        # collect calls + bound locals in the function\n",
    "        bare_names, qual_calls, bound_locals = _collect_calls_and_locals(target_node)\n",
    "\n",
    "        resolved_funcs: set[str] = set()\n",
    "\n",
    "        # ---- Bare calls: helper() ----\n",
    "        for name in bare_names:\n",
    "            # If the name is locally bound (param/assignment/etc.), we can't safely resolve it.\n",
    "            if name in bound_locals:\n",
    "                continue\n",
    "\n",
    "            # Same-file top-level function wins\n",
    "            if name in top_funcs:\n",
    "                resolved_funcs.add(f\"{this_module}.{name}\")\n",
    "                continue\n",
    "\n",
    "            # from pkg.mod import name [as alias]\n",
    "            if name in from_names:\n",
    "                full = from_names[name]  # e.g., 'pkg.mod.helper'\n",
    "                if full in by_mod_func:\n",
    "                    resolved_funcs.add(full)\n",
    "                    continue\n",
    "\n",
    "            # No project-wide name scan unless explicitly allowed\n",
    "            if aggressive_fallback:\n",
    "                for _fp, module_name, _node in by_name.get(name, []):\n",
    "                    # skip the exact same target function identity\n",
    "                    if module_name == this_module and name == func_name:\n",
    "                        continue\n",
    "                    resolved_funcs.add(f\"{module_name}.{name}\")\n",
    "\n",
    "        # ---- Qualified calls: utils.helper(), pkg.sub.mod.helper() ----\n",
    "        for root, chain in qual_calls:\n",
    "            if not chain:\n",
    "                continue\n",
    "\n",
    "            # If root is locally bound, treat as object, not module\n",
    "            if root in bound_locals:\n",
    "                continue\n",
    "\n",
    "            func = chain[-1]\n",
    "            prefix = chain[:-1]\n",
    "\n",
    "            # Root can come from either 'import ... as root' OR 'from ... import root as root'\n",
    "            base_mod = import_aliases.get(root)\n",
    "            if not base_mod:\n",
    "                # If root was imported via 'from X import root', that map points to X.root\n",
    "                maybe = from_names.get(root)\n",
    "                if maybe:\n",
    "                    # If 'root' is actually a submodule imported via 'from X import root'\n",
    "                    base_mod = maybe\n",
    "\n",
    "            if not base_mod:\n",
    "                continue  # unknown root â†’ skip\n",
    "\n",
    "            full_mod = \".\".join([base_mod] + prefix) if prefix else base_mod\n",
    "            candidate = f\"{full_mod}.{func}\"\n",
    "\n",
    "            if candidate in by_mod_func:\n",
    "                resolved_funcs.add(candidate)\n",
    "            elif aggressive_fallback:\n",
    "                for _fp, module_name, _node in by_name.get(func, []):\n",
    "                    resolved_funcs.add(f\"{module_name}.{func}\")\n",
    "        helper_function_paths = sorted(resolved_funcs)\n",
    "        if detailed_functions:\n",
    "            for func_path in helper_function_paths:\n",
    "                p, f = create_file_path(base_path, func_path)\n",
    "                # print(f, p)\n",
    "                helper_function_paths_final.append(extract_function_source_ast(\n",
    "                    file_path=p,\n",
    "                    func_or_qualname=f,\n",
    "                    include_helpers=detailed_functions,\n",
    "                    base_path=base_path,\n",
    "                    detailed_functions=recursive_helper,\n",
    "                ))\n",
    "        else:\n",
    "            helper_function_paths_final = helper_function_paths\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "        \"helpers\": helper_function_paths_final,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c4ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator, model_validator  # Pydantic v2\n",
    "\n",
    "class ParameterInputSchema(BaseModel):\n",
    "    function_path: str = Field(str, alias=\"function_path\")\n",
    "    include_helpers: bool = Field(False, alias=\"include_helpers\")\n",
    "    base_path: str = Field(str, alias=\"base_path\")\n",
    "    detailed_functions: bool = Field(False, alias=\"detailed_functions\")\n",
    "    recursive_helper: bool = Field(False, alias=\"recursive_helper\")\n",
    "    aggressive_fallback: bool = Field(False, alias=\"aggressive_fallback\")\n",
    "\n",
    "    # allow using field names instead of aliases and vice-versa\n",
    "    model_config = dict(populate_by_name=True)\n",
    "\n",
    "    # @field_validator(\"base_path\", mode=\"before\")\n",
    "    # @classmethod\n",
    "    # def _coerce_to_path(cls, v):\n",
    "    #     return Path(v).expanduser() if not isinstance(v, Path) else v\n",
    "\n",
    "    # @model_validator(mode=\"after\")\n",
    "    # def _validate_paths(self):\n",
    "    #     # Convert to Path\n",
    "    #     self.base_path = Path(self.base_path).resolve()\n",
    "    #     self.file_path = Path(self.file_path).resolve()\n",
    "\n",
    "    #     if not self.file_path.exists():\n",
    "    #         raise ValueError(f\"file_path does not exist: {self.file_path}\")\n",
    "    #     if not self.file_path.is_file():\n",
    "    #         raise ValueError(\"file_path must be a file\")\n",
    "\n",
    "    #     # Ensure file_path is within base_path\n",
    "    #     try:\n",
    "    #         self.file_path.relative_to(self.base_path)\n",
    "    #     except ValueError as e:\n",
    "    #         raise ValueError(\n",
    "    #             f\"file_path must be under base_path\\n  file: {self.file_path}\\n  base: {self.base_path}\"\n",
    "    #         ) from e\n",
    "    #     return self\n",
    "\n",
    "    # Back-compat property for code that still references the misspelling\n",
    "    @property\n",
    "    def reursive_helper(self) -> bool:\n",
    "        return self.recursive_helper\n",
    "\n",
    "    def to_kwargs(self) -> Dict[str, Any]:\n",
    "        \"\"\"Map schema to extract_function_source_ast kwargs (preserves original param names).\"\"\"\n",
    "        path, func = create_file_path(str(self.base_path), str(self.function_path))\n",
    "        return {\n",
    "            \"file_path\": path,\n",
    "            \"func_or_qualname\": func,\n",
    "            \"include_helpers\": self.include_helpers,\n",
    "            \"base_path\": str(self.base_path),\n",
    "            \"detailed_functions\": self.detailed_functions,\n",
    "            \"recursive_helper\": self.recursive_helper,   # keep original name expected by your function\n",
    "            \"aggressive_fallback\": self.aggressive_fallback,\n",
    "        }\n",
    "\n",
    "def extract_function_source(\n",
    "        params: ParameterInputSchema,  # set True to allow cross-project name fallback\n",
    "        # tool_context: ToolContext\n",
    "    ) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Wrapper around `extract_function_source_ast` that accepts a validated\n",
    "    `ParameterInputSchema` and forwards its fields as keyword arguments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : ParameterInputSchema\n",
    "        Contains:\n",
    "          - function_path (str): Path to the function/method to extract.\n",
    "          - include_helpers (bool): If True, also return helper function *paths* discovered\n",
    "            from calls inside the target, searching across the project.\n",
    "          - base_path (str): Project root directory. Only files under this root are considered.\n",
    "          - detailed_functions (bool): If True, include detailed information about function\n",
    "            arguments and return types.\n",
    "          - recursive_helper (bool): If True, include helper functions found in the same file.\n",
    "          - aggressive_fallback (bool): If True, when binding can't be proven, include all\n",
    "            same-named top-level functions found across the project.\n",
    "    tool_context : ToolContext\n",
    "        Tool context (e.g., session/runtime context) passed through to the extractor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        {\n",
    "          \"code\": str,\n",
    "          \"start_line\": int,\n",
    "          \"end_line\": int,\n",
    "          \"function\": str,\n",
    "          \"file\": str,\n",
    "          \"helpers\": List[str] | List[Dict[str, Any]]  # depends on detailed_helpers flags\n",
    "        }\n",
    "    \"\"\"\n",
    "    return extract_function_source_ast(\n",
    "        # tool_context=tool_context,\n",
    "        **params.to_kwargs(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d07c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JonathanChackoPattas\\OneDrive - Maritime Support Solutions\\Desktop\\MSS-Automation\\Inventory\\views_pack\\terminal.py \n",
      "process_exe_data()\n",
      "{\n",
      "  \"code\": \"# Extracted from terminal.py:585-1563\\ndef process_exe_data(request, session_id):\\n    if session_id != \\\"*\\\":\\n        saudi_exe = SaudiExe.objects.get(session_id=session_id)\\n        completerd = saudi_exe.flag_completed\\n        if completerd:\\n            messages.error(request, 'Data already processed.')\\n            return redirect('inventory:saudi_exe')\\n        TSR = saudi_exe.flag_tsr\\n        EXE_Model = EXE_tsr_ReportData if TSR else EXE_daily_ReportData\\n        EXE_Search_Base = {\\n            \\\"session_id\\\": session_id, 'proccessed': False, 'error': False\\n        }\\n        if TSR:\\n            EXE_Search_Base['deleted'] = False\\n        df = reading_as_df_From_ORM(\\n            Model= EXE_Model,\\n            condition= EXE_Search_Base,\\n            ignore_id=True\\n        )\\n    else:\\n        df = pd.DataFrame(list(get_error_session_ids()))\\n        EXE_Model = EXE_daily_ReportData\\n        completerd = False\\n        TSR = False\\n    # NOTE~TODO make another DF showing whatever is already Proccessed so it can all be ACCEPT + note of `Already Proccessed` on Frontend.\\n    uiy_check = False\\n    if df.empty:\\n        if saudi_exe.document_type != \\\"RSGT-UIY_Report\\\":\\n            messages.error(request, 'No data found | Contact Admin.')\\n            return redirect('inventory:saudi_exe')\\n        else:\\n            uiy_check = True\\n            df = pd.DataFrame(columns=['proccessed', 'error', 'SNTC_DATE', 'RCVC_DATE', 'SNTS_DATE', 'RCVS_DATE'])\\n\\n    if TSR:\\n        TSR_DICT = {\\n            \\\"IMP_TSR_VSL\\\": saudi_exe.IMP_TSR_VSL, \\\"IMP_TSR_VOY\\\": saudi_exe.IMP_TSR_VOY, \\\"IMP_TSR_DATE\\\": saudi_exe.IMP_TSR_DATE,\\n            \\\"EXP_TSR_VSL\\\": saudi_exe.EXP_TSR_VSL, \\\"EXP_TSR_VOY\\\": saudi_exe.EXP_TSR_VOY, \\\"EXP_TSR_DATE\\\": saudi_exe.EXP_TSR_DATE,\\n        }\\n        for key, value in TSR_DICT.items():\\n            df[key] = value\\n        # Get container-session tuples\\n        new_rows = list(UnScannedBLs.objects\\n                        .filter(session_id=session_id, flag_completed=False)\\n                        .values_list('CONTAINER_NUMBER', 'session_id'))\\n        if new_rows:\\n            # Efficient filtering using Q objects\\n            filters = Q()\\n            for cn, ses in new_rows:\\n                filters |= Q(CONTAINER_NUMBER=cn, session_id=ses)\\n            # Query and fetch BL_NUMBER values\\n            rowzt = EXE_tsr_ReportData.objects.filter(filters).values_list('BL_NUMBER', flat=True)\\n            # Remove duplicates and fill nulls with empty string\\n            BAN_BL_LIST = list({bl or '' for bl in rowzt})\\n        else:\\n            BAN_BL_LIST = []\\n    else:\\n        BAN_BL_LIST = []\\n    if session_id != \\\"*\\\":\\n        df.drop(columns=['proccessed', 'error'], inplace=True) # , 'session_id'\\n    date_cols = ['SNTC_DATE', 'RCVC_DATE', 'SNTS_DATE', 'RCVS_DATE'] if not TSR else ['IMP_TSR_DATE', 'EXP_TSR_DATE']\\n    df[date_cols] = df[date_cols].apply(pd.to_datetime, errors='coerce')\\n    rows = df.copy().iterrows() # df.copy().to_dict(orient='records')\\n    def takeRow2Data(mODEL, row):\\n        columns = [f.name for f in mODEL._meta.get_fields() if f.name != 'id']\\n        data = {col: getattr(row, col) for col in columns if hasattr(row, col)}\\n        return data\\n    df['STATUS'] = False\\n    df['REMARKS'] = None\\n    for index, row in rows: # for row in rows:\\n        try:\\n            CONTAINER_NUMBER = row['CONTAINER_NUMBER']\\n            STATUS = False\\n            note = None\\n            if TSR: # NOTE: The Only Problem is that if the BL has Other Containers which isnt in TSR but in BL.\\n                TSR_PROCESS = row['PROCESS']\\n                if 'INVOICE_PRINCIPAL_NAME' in row:\\n                    # If INVOICE_PRINCIPAL_NAME is already set, use it\\n                    if row['INVOICE_PRINCIPAL_NAME'] not in [None, np.nan, \\\"\\\"]:\\n                        principal_confirm = row['INVOICE_PRINCIPAL_NAME']\\n                    else:\\n                        principal_confirm = row['LINE']\\n                else:\\n                    principal_confirm = row['LINE']\\n                row['LINE'] = principal_confirm\\n                if row['BL_NUMBER'] in BAN_BL_LIST:\\n                    STATUS = False\\n                    note = f\\\"BL {row['BL_NUMBER']} isn't Confirmed yet, so can't be processed.\\\"\\n                elif TSR_PROCESS == \\\"I\\\":\\n                    tb = \\\"BLTable for Imports.\\\"\\n                    if not Inventory.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False).exists():\\n                        dataForInventory = {\\n                            \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                            \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                            \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                            \\\"IMP_VESSEL_VOY\\\": row['IMP_TSR_VSL'] + \\\"/\\\" + row['IMP_TSR_VOY'],\\n                            \\\"DISCHARGE_STATUS\\\": row['EMPTY_FULL'],\\n                            \\\"IMP_POL\\\": row['ALT_PORT'] if 'ALT_PORT' in row else \\\"\\\",\\n                            \\\"IMP_POD\\\": row['PORT'],\\n                            \\\"IMP_FPOD\\\": row['PORT'],\\n                            \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                            \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                            \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                            \\\"DISCHARGE_DATE\\\": row['IMP_TSR_DATE'],\\n                            \\\"DISCHARGE_AT_ICD\\\": row['IMP_TSR_DATE'],\\n                            \\\"IMPORT_BL_NUMBER\\\": row['BL_NUMBER'],\\n                            \\\"session_id\\\": session_id,\\n                        }\\n                        BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\" \\n                        if BL_Exists:\\n                            PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                            if PreAlert_Check.exists():\\n                                first = True\\n                                for prealert_row in PreAlert_Check:\\n                                    # prealert_row = PreAlert_Check.first()\\n                                    for key, value in {\\n                                        # \\\"CONTAINER_SIZE\\\": prealert_row.CONTAINER_SIZE,\\n                                        # \\\"CONTAINER_TYPE\\\": prealert_row.CONTAINER_TYPE,\\n                                        \\\"IMP_POL\\\": prealert_row.IMP_POL,\\n                                        # \\\"IMP_POD\\\": prealert_row.IMP_POD,\\n                                        # \\\"IMP_FPOD\\\": prealert_row.IMP_FPOD,\\n                                        # \\\"IMPORT_BL_NUMBER\\\": prealert_row.BL_NUMBER,\\n                                        \\\"CLIENT_NAME\\\": prealert_row.CLIENT_NAME,\\n                                        \\\"LOCATION_NAME\\\": prealert_row.LOCATION_NAME,\\n                                        \\\"PRINCIPAL_NAMES\\\": prealert_row.PRINCIPAL_NAMES\\n                                    }.items():\\n                                        if key in dataForInventory.keys():\\n                                            if value != dataForInventory[key] and value not in ['', None, np.nan]:\\n                                                dataForInventory[key] = value\\n                                    # if prealert_row.IMP_VESSEL not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                    #     dataForInventory['IMP_VESSEL_VOY'] = prealert_row.IMP_VESSEL + \\\"/\\\" + prealert_row.IMP_VOYAGE\\n                                    if first:\\n                                        dataForInventory['session_id'] = prealert_row.session_id\\n                                        PreAlertTracker_Old.objects.create(**takeRow2Data(PreAlertTracker_Old, prealert_row)) # PreAlertTracker_Old.objects.create(**prealert_row.__dict__)\\n                                        first = False\\n                                    prealert_row.delete()\\n                            ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                            if ImportBL_Check.exists():\\n                                first = True\\n                                for ibl_row in ImportBL_Check:\\n                                    # ibl_row = ImportBL_Check.first()\\n                                    for key, value in {\\n                                        # \\\"CONTAINER_SIZE\\\": ibl_row.CONTAINER_SIZE,\\n                                        # \\\"CONTAINER_TYPE\\\": ibl_row.CONTAINER_TYPE,\\n                                        \\\"IMP_POL\\\": ibl_row.IMP_POL,\\n                                        # \\\"IMP_POD\\\": ibl_row.IMP_POD,\\n                                        # \\\"IMP_FPOD\\\": ibl_row.IMP_FPOD,\\n                                        # \\\"IMPORT_BL_NUMBER\\\": ibl_row.BL_NUMBER,\\n                                        \\\"CLIENT_NAME\\\": ibl_row.DELIVERYAGENT_NAME,\\n                                        \\\"LOCATION_NAME\\\": ibl_row.LOCATION_NAME,\\n                                        \\\"PRINCIPAL_NAMES\\\": ibl_row.PRINCIPAL_NAMES\\n                                    }.items():\\n                                        if key in dataForInventory.keys():\\n                                            if value != dataForInventory[key] and value not in ['', None, np.nan]:\\n                                                dataForInventory[key] = value\\n                                    # if str(ibl_row.IMP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                    #     dataForInventory['IMP_VESSEL_VOY'] = ibl_row.IMP_VSL_VOY\\n                                    if first:\\n                                        dataForInventory['session_id'] = ibl_row.session_id\\n                                        IBLD_HISTORY.objects.create(**takeRow2Data(IBLD_HISTORY, ibl_row)) # IBLD_HISTORY.objects.create(**ibl_row.__dict__)\\n                                        first = False\\n                                    ibl_row.delete()\\n                        Inventory.objects.create(**dataForInventory)\\n                        # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                        STATUS = True\\n                        # note = f\\\"Data Moved Successfully from {tb} to Inventory.\\\"\\n                    else:\\n                        # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n                        STATUS = False\\n                        note = f\\\"Container already exists in INVENTORY: {CONTAINER_NUMBER}.\\\"\\n                elif TSR_PROCESS == \\\"E\\\":\\n                    tb = \\\"Inventory for Exports.\\\"\\n                    dataForInventory = {\\n                        # \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                        # \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                        # \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                        \\\"EXP_VESSEL_VOY\\\": row['EXP_TSR_VSL'] + \\\"/\\\" + row['EXP_TSR_VOY'],\\n                        \\\"SAILING_DATE\\\": row['EXP_TSR_DATE'],\\n                        \\\"EXPORT_BL_NUMBER\\\": row['BL_NUMBER'],\\n                        \\\"LOADING_STATUS\\\": row['EMPTY_FULL'],\\n                        \\\"EMPTY_FULL\\\": row['EMPTY_FULL'],\\n                        \\\"EXP_POL\\\": row['PORT'],\\n                        \\\"EXP_POD\\\": row['ALT_PORT'] if 'ALT_PORT' in row else \\\"\\\",\\n                        \\\"EXP_FPOD\\\": row['ALT_PORT'] if 'ALT_PORT' in row else \\\"\\\",\\n                        # \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                        # \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                        # \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                        \\\"session_id\\\": session_id,\\n                    }\\n                    BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                    Inventory_check = Inventory.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False)\\n                    if Inventory_check.exists():\\n                        Inventory_ROW = Inventory_check.first()\\n                        if BL_Exists:\\n                            ExportGrouping_Check = ExportsGrouper.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                            if ExportGrouping_Check.exists():\\n                                # for eg_row in ExportGrouping_Check: # NOTE-TODO (Refer to ABOVE.)\\n                                eg_row = ExportGrouping_Check.first()\\n                                for key, value in {\\n                                    # \\\"SAILING_DATE\\\": eg_row.SAILING_DATE,\\n                                    \\\"EXPORT_BL_NUMBER\\\": eg_row.BL_NUMBER,\\n                                }.items():\\n                                    if key in dataForInventory.keys():\\n                                        if value != dataForInventory[key] and value not in ['', None, np.nan]:\\n                                            dataForInventory[key] = value\\n                                dataForInventory['session_id'] = eg_row.internalBookingNumber # eg_row.session_id\\n                                SI_Check = ExportsSITable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                if SI_Check.exists():\\n                                    ebl_row = SI_Check.first()\\n                                    for key, value in {\\n                                        \\\"EXP_POL\\\": ebl_row.EXP_POL,\\n                                        \\\"EXP_POD\\\": ebl_row.EXP_POD,\\n                                        \\\"EXP_FPOD\\\": ebl_row.EXP_FPOD,\\n                                        \\\"EXPORT_BL_NUMBER\\\": ebl_row.BL_NUMBER,\\n                                        \\\"BOOKING_NO\\\": ebl_row.BOOKING_NUMBER,\\n                                    }.items():\\n                                        if key in dataForInventory.keys():\\n                                            if value != dataForInventory[key] and value not in ['', None, np.nan]:\\n                                                dataForInventory[key] = value\\n                                    if str(ebl_row.EXP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                        dataForInventory['EXP_VESSEL_VOY'] = ebl_row.EXP_VSL_VOY\\n                                    EBLD_ERROR.objects.create(**takeRow2Data(EBLD_ERROR, ebl_row)) # EBLD_ERROR.objects.create(**ebl_row.__dict__)\\n                                BL_Check = ExportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                if BL_Check.exists():\\n                                    ebl_row = BL_Check.first()\\n                                    for key, value in {\\n                                        \\\"EXP_POL\\\": ebl_row.EXP_POL,\\n                                        \\\"EXP_POD\\\": ebl_row.EXP_POD,\\n                                        \\\"EXP_FPOD\\\": ebl_row.EXP_FPOD,\\n                                        \\\"EXPORT_BL_NUMBER\\\": ebl_row.BL_NUMBER,\\n                                        \\\"BOOKING_NO\\\": ebl_row.BOOKING_NUMBER,\\n                                    }.items():\\n                                        if key in dataForInventory.keys():\\n                                            if value != dataForInventory[key] and value not in ['', None, np.nan]:\\n                                                dataForInventory[key] = value\\n                                    if str(ebl_row.EXP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                        dataForInventory['EXP_VESSEL_VOY'] = ebl_row.EXP_VSL_VOY\\n                                    EBLD_HISTORY.objects.create(**takeRow2Data(EBLD_HISTORY, ebl_row)) # EBLD_HISTORY.objects.create(**ebl_row.__dict__)\\n                                ebl_row.delete()\\n                                ExportGrouperHISTORY.objects.create(**takeRow2Data(ExportGrouperHISTORY, eg_row)) # ExportGrouperHISTORY.objects.create(**eg_row.__dict__)\\n                                eg_row.delete()\\n                        for key, value in dataForInventory.items():\\n                            setattr(Inventory_ROW, key, value)  # Update fields dynamically\\n                        Inventory_ROW.flag_history = True\\n                        # Inventory_ROW.save()\\n                        Inventory_ROW.added_on = addedOnValue()\\n                        Inventory_ROW.added_by = str(request.user)\\n                        Inventory_ROW.save()\\n                        move_inventory(False) # Implement the Function\\n                        # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                        STATUS = True\\n                        # note = f\\\"Data Moved Successfully from {tb} to Inventory.\\\"\\n                    else:\\n                        STATUS = False\\n                        note = f\\\"Container not found in {tb}.\\\"\\n                elif TSR_PROCESS == \\\"T\\\": # if Same TSR is Provided Multiple Times then it will be a POSSIBLE Problem for Transhipment Section!\\n                    if saudi_exe.port_choice == \\\"SGP\\\":\\n                        tb = \\\"Tables related to Transhipment.\\\"\\n                        ran = False\\n                        BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                        if BL_Exists:\\n                            alreadyProccessed = TranshipmentHistory.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row['BL_NUMBER']).exists() or TranshipmentHistory.objects.filter(BL_NUMBER=row['BL_NUMBER']).exists() # , flag_history=True\\n                        else: # If Empty Assume Not Proccessed\\n                            alreadyProccessed = False\\n                        if row['DETAIL_PROCESS'] == \\\"OUT\\\":\\n                            isOUT = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row['BL_NUMBER'], flag_history=False).exists() if BL_Exists or row['EMPTY_FULL'] == \\\"FULL\\\" else Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False).exists()\\n                            if isOUT:\\n                                tb = \\\"Transhipment for OUT\\\"\\n                                dataForTranshipment = {\\n                                    # \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                                    # \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                                    # \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                                    \\\"LOADING_VESSEL_VOY\\\": row['EXP_TSR_VSL'] + \\\"/\\\" + row['EXP_TSR_VOY'],\\n                                    \\\"SAILING_DATE\\\": row['EXP_TSR_DATE'],\\n                                    \\\"BL_NUMBER\\\": row['BL_NUMBER'], # Need to Check if BL Exists\\n                                    \\\"EMPTY_FULL\\\": row['EMPTY_FULL'], # Need to Check if BL Exists\\n                                    \\\"TRANSHIPMENT_PORT\\\": row['PORT'], # \\\"POD\\\": row['PORT'],\\n                                    # \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                                    # \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                                    # \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                                    \\\"session_id\\\": session_id,\\n                                }\\n                                BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                Transhipment_check = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False)\\n                                if Transhipment_check.exists():\\n                                    # for Transhipment_ROW in ExportGrouping_Check: # NOTE-TODO (Refer to ABOVE.)\\n                                    Transhipment_ROW = Transhipment_check.first()\\n                                    # Preserve existing DISCHARGE_DATE if it exists and TSR data doesn't have it\\n                                    for key, value in dataForTranshipment.items():\\n                                        if key == \\\"DISCHARGE_DATE\\\":\\n                                            if value in [None, np.nan, \\\"\\\"]: # and hasattr(Transhipment_ROW, 'DISCHARGE_DATE'):\\n                                                continue # Preserve DISCHARGE_DATE when setting SAILING_DATE\\n                                            pass\\n                                        setattr(Transhipment_ROW, key, value)  # Update fields dynamically\\n                                    Transhipment_ROW.flag_history = True\\n                                    # Transhipment_ROW.save()\\n                                    Transhipment_ROW.added_on = addedOnValue()\\n                                    Transhipment_ROW.added_by = str(request.user)\\n                                    Transhipment_ROW.save()\\n                                    move_inventory(False) # Implement the Function\\n                                    # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                                    STATUS = True\\n                                    # note = f\\\"Data Moved Successfully from {tb} to Transhipment.\\\"\\n                                move_inventory(False) # Implement the Function\\n                                # note = f\\\"Transhipment Loading Data Updated Successfully.\\\"\\n                                ran = True\\n                            else:\\n                                STATUS = False\\n                                note = \\\"Transhipment Process for OUT but No Data found in Transhipment Table.\\\"\\n                        else: # row['DETAIL_PROCESS'] == \\\"IN\\\"\\n                            tb = \\\"BLTable for Transhipment IN\\\"\\n                            dataForTranshipment = {\\n                                \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                                \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                                \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                                \\\"DISCHARGE_VESSEL_VOY\\\": row['IMP_TSR_VSL'] + \\\"/\\\" + row['IMP_TSR_VOY'],\\n                                \\\"EMPTY_FULL\\\": row['EMPTY_FULL'],\\n                                \\\"TRANSHIPMENT_PORT\\\": row['PORT'], # \\\"POD\\\": row['PORT'],\\n                                \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                                \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                                \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                                \\\"DISCHARGE_DATE\\\": row['IMP_TSR_DATE'],\\n                                \\\"BL_NUMBER\\\": row['BL_NUMBER'],\\n                                \\\"session_id\\\": session_id,\\n                            }\\n                            # Transhipment IN\\n                            if ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER).exists() and not ran:\\n                                Transhipment_check = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False)\\n                                if Transhipment_check.exists():\\n                                    note = f\\\"Container Already Found in {tb}.\\\"\\n                                    BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                    if BL_Exists:\\n                                        PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                        if PreAlert_Check.exists():\\n                                            prealert_row = PreAlert_Check.first()\\n                                            # PreAlertTracker_Error.objects.create(**takeRow2Data(PreAlertTracker_Error, prealert_row)) # PreAlertTracker_Error.objects.create(**prealert_row.__dict__) # To Create\\n                                            prealert_row.delete()\\n                                        ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                        if ImportBL_Check.exists():\\n                                            tbl_row = ImportBL_Check.first()\\n                                            TBLD_ERROR.objects.create(**takeRow2Data(TBLD_ERROR, tbl_row))  # TBLD_ERROR.objects.create(**tbl_row.__dict__)\\n                                            tbl_row.delete()\\n                                else:\\n                                    BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                    if BL_Exists:\\n                                        PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                        if PreAlert_Check.exists():\\n                                            first = True\\n                                            for prealert_row in PreAlert_Check:\\n                                                # prealert_row = PreAlert_Check.first()\\n                                                for key, value in {\\n                                                #     \\\"CONTAINER_SIZE\\\": prealert_row.CONTAINER_SIZE,\\n                                                #     \\\"CONTAINER_TYPE\\\": prealert_row.CONTAINER_TYPE,\\n                                                    \\\"POL\\\": prealert_row.IMP_POL,\\n                                                #     \\\"TRANSHIPMENT_PORT\\\": prealert_row.IMP_POD,\\n                                                #     \\\"FPOD\\\": prealert_row.IMP_FPOD,\\n                                                #     \\\"BL_NUMBER\\\": prealert_row.BL_NUMBER,\\n                                                    \\\"CLIENT_NAME\\\": prealert_row.CLIENT_NAME,\\n                                                    \\\"LOCATION_NAME\\\": prealert_row.LOCATION_NAME,\\n                                                    \\\"PRINCIPAL_NAMES\\\": prealert_row.PRINCIPAL_NAMES\\n                                                }.items():\\n                                                    if key in dataForTranshipment.keys():\\n                                                        if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                            dataForTranshipment[key] = value\\n                                                # if prealert_row.IMP_VESSEL not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                                #     dataForTranshipment['DISCHARGE_VESSEL_VOY'] = prealert_row.IMP_VESSEL + \\\"/\\\" + prealert_row.IMP_VOYAGE\\n                                                if first:\\n                                                    dataForTranshipment['session_id'] = prealert_row.session_id\\n                                                    PreAlertTracker_Old.objects.create(**takeRow2Data(PreAlertTracker_Old, prealert_row)) # PreAlertTracker_Old.objects.create(**prealert_row.__dict__)\\n                                                    first = False\\n                                                prealert_row.delete()\\n                                        ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                        if ImportBL_Check.exists():\\n                                            first = True\\n                                            for tbl_row in ImportBL_Check:\\n                                                # tbl_row = ImportBL_Check.first()\\n                                                for key, value in {\\n                                                #     \\\"CONTAINER_SIZE\\\": tbl_row.CONTAINER_SIZE,\\n                                                #     \\\"CONTAINER_TYPE\\\": tbl_row.CONTAINER_TYPE,\\n                                                    \\\"POL\\\": tbl_row.IMP_POL,\\n                                                #     \\\"TRANSHIPMENT_PORT\\\": tbl_row.IMP_POD,\\n                                                #     \\\"FPOD\\\": tbl_row.IMP_FPOD,\\n                                                #     \\\"BL_NUMBER\\\": tbl_row.BL_NUMBER,\\n                                                    \\\"CLIENT_NAME\\\": tbl_row.DELIVERYAGENT_NAME,\\n                                                    \\\"LOCATION_NAME\\\": tbl_row.LOCATION_NAME,\\n                                                    \\\"PRINCIPAL_NAMES\\\": tbl_row.PRINCIPAL_NAMES\\n                                                }.items():\\n                                                    if key in dataForTranshipment.keys():\\n                                                        if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                            dataForTranshipment[key] = value\\n                                                # if str(tbl_row.IMP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                                #     dataForTranshipment['DISCHARGE_VESSEL_VOY'] = tbl_row.IMP_VSL_VOY\\n                                                if first:\\n                                                    dataForTranshipment['session_id'] = tbl_row.session_id\\n                                                    TBLD_HISTORY.objects.create(**takeRow2Data(TBLD_HISTORY, tbl_row)) # TBLD_HISTORY.objects.create(**tbl_row.__dict__)\\n                                                    first = False\\n                                                tbl_row.delete()\\n                                    Transhipment.objects.create(**dataForTranshipment)\\n                                    # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                                    STATUS = True\\n                                    note = f\\\"Transhipment Discharge Data Updated Successfully.\\\"\\n                            else:\\n                                STATUS = False\\n                                note = f\\\"Container not found in {tb}.\\\"\\n                    # elif saudi_exe.port_choice == \\\"RSGT\\\": ## Check with SaudiExe if \\\"RSGT\\\"\\n                    #     STATUS = False\\n                    #     note = \\\"Transhipment Upload to be Done using Unit In Yard (UIY) Report.\\\" # \\\"Transhipment Process for RSGT is Disabled for now with the Updated Implementation of 'Unit in Yard'.\\\"\\n                    else: # saudi_exe.port_choice == \\\"DPW\\\": | or now \\\"RSGT-OUT\\\"\\n                        tb = \\\"Tables related to Transhipment.\\\"\\n                        ran = False\\n                        BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                        if BL_Exists:\\n                            alreadyProccessed = TranshipmentHistory.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row['BL_NUMBER']).exists() or TranshipmentHistory.objects.filter(BL_NUMBER=row['BL_NUMBER']).exists() # , flag_history=True\\n                        else: # If Empty Assume Not Proccessed\\n                            alreadyProccessed = False\\n                        if not alreadyProccessed:\\n                            # Transhipment OUT\\n                            isOUT = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row['BL_NUMBER'], flag_history=False).exists() if BL_Exists or row['EMPTY_FULL'] == \\\"FULL\\\" else Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False).exists()\\n                            if isOUT:\\n                                tb = \\\"Transhipment for OUT\\\"\\n                                dataForTranshipment = {\\n                                    # \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                                    # \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                                    # \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                                    \\\"LOADING_VESSEL_VOY\\\": row['EXP_TSR_VSL'] + \\\"/\\\" + row['EXP_TSR_VOY'],\\n                                    \\\"SAILING_DATE\\\": row['EXP_TSR_DATE'],\\n                                    \\\"BL_NUMBER\\\": row['BL_NUMBER'], # Need to Check if BL Exists\\n                                    \\\"EMPTY_FULL\\\": row['EMPTY_FULL'], # Need to Check if BL Exists\\n                                    \\\"TRANSHIPMENT_PORT\\\": row['PORT'], # \\\"POD\\\": row['PORT'],\\n                                    # \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                                    # \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                                    # \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                                    \\\"session_id\\\": session_id,\\n                                }\\n                                BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                Transhipment_check = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, flag_history=False)\\n                                if Transhipment_check.exists():\\n                                    # for Transhipment_ROW in ExportGrouping_Check: # NOTE-TODO (Refer to ABOVE.)\\n                                    Transhipment_ROW = Transhipment_check.first()\\n                                    # Store existing DISCHARGE_DATE to preserve it\\n                                    existing_discharge_date = getattr(Transhipment_ROW, 'DISCHARGE_DATE', None)\\n                                    # This Logic is that Discharge_Date and Sailing_Date Not Same BUT it should be for Vessel Voyage BUT since we can't properly Compare that this is TEMP LOGIC.\\n                                    if existing_discharge_date != dataForTranshipment['SAILING_DATE']: # .get('SAILING_DATE')\\n                                        for key, value in dataForTranshipment.items():\\n                                            if saudi_exe.port_choice == \\\"RSGT\\\" and key == \\\"LOADING_VESSEL_VOY\\\":\\n                                                pass # To Sleepy to think just patching like this - Jonathan (22/07/2025)\\n                                            else: # if not(saudi_exe.port_choice == \\\"RSGT\\\" and key == \\\"LOADING_VESSEL_VOY\\\"):\\n                                                setattr(Transhipment_ROW, key, value)  # Update fields dynamically\\n                                        # Preserve existing DISCHARGE_DATE if it was set and we're only updating SAILING_DATE\\n                                        if existing_discharge_date and 'DISCHARGE_DATE' not in dataForTranshipment:\\n                                            Transhipment_ROW.DISCHARGE_DATE = existing_discharge_date\\n                                        elif 'DISCHARGE_DATE' in dataForTranshipment:\\n                                            if dataForTranshipment['DISCHARGE_DATE'] in [None, np.nan, \\\"\\\"]:\\n                                                # If DISCHARGE_DATE is not provided, preserve the existing one\\n                                                Transhipment_ROW.DISCHARGE_DATE = existing_discharge_date\\n                                        Transhipment_ROW.flag_history = True\\n                                        # Transhipment_ROW.save()\\n                                        Transhipment_ROW.added_on = addedOnValue()\\n                                        Transhipment_ROW.added_by = str(request.user)\\n                                    Transhipment_ROW.save()\\n                                    move_inventory(False) # Implement the Function\\n                                    # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                                    STATUS = True\\n                                    # note = f\\\"Data Moved Successfully from {tb} to Transhipment.\\\"\\n                                move_inventory(False) # Implement the Function\\n                                # note = f\\\"Transhipment Loading Data Updated Successfully.\\\"\\n                                ran = True\\n                            if saudi_exe.port_choice != \\\"RSGT\\\":\\n                                tb = \\\"BLTable for Transhipment IN\\\"\\n                                dataForTranshipment = {\\n                                    \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                                    \\\"CONTAINER_SIZE\\\": row['CONTAINER_SIZE'],\\n                                    \\\"CONTAINER_TYPE\\\": row['CONTAINER_TYPE'],\\n                                    \\\"DISCHARGE_VESSEL_VOY\\\": row['IMP_TSR_VSL'] + \\\"/\\\" + row['IMP_TSR_VOY'],\\n                                    \\\"EMPTY_FULL\\\": row['EMPTY_FULL'],\\n                                    \\\"TRANSHIPMENT_PORT\\\": row['PORT'], # \\\"POD\\\": row['PORT'],\\n                                    \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                                    \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                                    \\\"PRINCIPAL_NAMES\\\": row['LINE'],\\n                                    \\\"DISCHARGE_DATE\\\": row['IMP_TSR_DATE'],\\n                                    \\\"BL_NUMBER\\\": row['BL_NUMBER'],\\n                                    \\\"session_id\\\": session_id,\\n                                }\\n                                # Transhipment IN\\n                                if ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER).exists() and not ran:\\n                                    if STATUS:\\n                                        note = f\\\"Container Already Found in {tb}.\\\"\\n                                        BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                        if BL_Exists:\\n                                            PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                            if PreAlert_Check.exists():\\n                                                prealert_row = PreAlert_Check.first()\\n                                                # PreAlertTracker_Error.objects.create(**takeRow2Data(PreAlertTracker_Error, prealert_row)) # PreAlertTracker_Error.objects.create(**prealert_row.__dict__) # To Create\\n                                                prealert_row.delete()\\n                                            ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                            if ImportBL_Check.exists():\\n                                                tbl_row = ImportBL_Check.first()\\n                                                TBLD_ERROR.objects.create(**takeRow2Data(TBLD_ERROR, tbl_row))  # TBLD_ERROR.objects.create(**tbl_row.__dict__)\\n                                                tbl_row.delete()\\n                                    else:\\n                                        BL_Exists = row['BL_NUMBER'] not in ['', None, np.nan, \\\" \\\"] # or row['EMPTY_FULL'] == \\\"FULL\\\"\\n                                        if BL_Exists:\\n                                            PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                            if PreAlert_Check.exists():\\n                                                first = True\\n                                                for prealert_row in PreAlert_Check:\\n                                                    # prealert_row = PreAlert_Check.first()\\n                                                    for key, value in {\\n                                                        # \\\"CONTAINER_SIZE\\\": prealert_row.CONTAINER_SIZE,\\n                                                        # \\\"CONTAINER_TYPE\\\": prealert_row.CONTAINER_TYPE,\\n                                                        \\\"POL\\\": prealert_row.IMP_POL,\\n                                                        # \\\"TRANSHIPMENT_PORT\\\": prealert_row.IMP_POD,\\n                                                        # \\\"FPOD\\\": prealert_row.IMP_FPOD,\\n                                                        # \\\"BL_NUMBER\\\": prealert_row.BL_NUMBER,\\n                                                        \\\"CLIENT_NAME\\\": prealert_row.CLIENT_NAME,\\n                                                        \\\"LOCATION_NAME\\\": prealert_row.LOCATION_NAME,\\n                                                        \\\"PRINCIPAL_NAMES\\\": prealert_row.PRINCIPAL_NAMES\\n                                                    }.items():\\n                                                        if key in dataForTranshipment.keys():\\n                                                            if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                                dataForTranshipment[key] = value\\n                                                    # if prealert_row.IMP_VESSEL not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                                    #     dataForTranshipment['DISCHARGE_VESSEL_VOY'] = prealert_row.IMP_VESSEL + \\\"/\\\" + prealert_row.IMP_VOYAGE\\n                                                    if first:\\n                                                        dataForTranshipment['session_id'] = prealert_row.session_id\\n                                                        PreAlertTracker_Old.objects.create(**takeRow2Data(PreAlertTracker_Old, prealert_row)) # PreAlertTracker_Old.objects.create(**prealert_row.__dict__)\\n                                                        first = False\\n                                                    prealert_row.delete()\\n                                            ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER)\\n                                            if ImportBL_Check.exists():\\n                                                first = True\\n                                                for tbl_row in ImportBL_Check:\\n                                                    # tbl_row = ImportBL_Check.first()\\n                                                    for key, value in {\\n                                                        # \\\"CONTAINER_SIZE\\\": tbl_row.CONTAINER_SIZE,\\n                                                        # \\\"CONTAINER_TYPE\\\": tbl_row.CONTAINER_TYPE,\\n                                                        \\\"POL\\\": tbl_row.IMP_POL,\\n                                                        # \\\"TRANSHIPMENT_PORT\\\": tbl_row.IMP_POD,\\n                                                        # \\\"FPOD\\\": tbl_row.IMP_FPOD,\\n                                                        # \\\"BL_NUMBER\\\": tbl_row.BL_NUMBER,\\n                                                        \\\"CLIENT_NAME\\\": tbl_row.DELIVERYAGENT_NAME,\\n                                                        \\\"LOCATION_NAME\\\": tbl_row.LOCATION_NAME,\\n                                                        \\\"PRINCIPAL_NAMES\\\": tbl_row.PRINCIPAL_NAMES\\n                                                    }.items():\\n                                                        if key in dataForTranshipment.keys():\\n                                                            if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                                dataForTranshipment[key] = value\\n                                                    # if str(tbl_row.IMP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                                    #     dataForTranshipment['DISCHARGE_VESSEL_VOY'] = tbl_row.IMP_VSL_VOY\\n                                                    if first:\\n                                                        dataForTranshipment['session_id'] = tbl_row.session_id\\n                                                        TBLD_HISTORY.objects.create(**takeRow2Data(TBLD_HISTORY, tbl_row)) # TBLD_HISTORY.objects.create(**tbl_row.__dict__)\\n                                                        first = False\\n                                                    tbl_row.delete()\\n                                        Transhipment.objects.create(**dataForTranshipment)\\n                                        # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                                        STATUS = True\\n                                        note = f\\\"Transhipment Discharge Data Updated Successfully.\\\"\\n                                elif not ran:\\n                                    Transhipment.objects.create(**dataForTranshipment)\\n                                    # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                                    STATUS = True\\n                                    note = f\\\"Transhipment Discharge Data Updated Successfully.\\\"\\n                                # else:\\n                                #     pass\\n                                if not STATUS:\\n                                    note = f\\\"Container not found in {tb}.\\\"\\n                            else:\\n                                STATUS = False\\n                                note = \\\"Transhipment `IN` Upload to be Done using Unit In Yard (UIY) Report.\\\" # \\\"Transhipment Process for RSGT is Disabled for now with the Updated Implementation of 'Unit in Yard'.\\\"\\n                        else:\\n                            STATUS = False\\n                            note = f\\\"Container already Proccessed & Found in TB History\\\"\\n                else:\\n                    STATUS = False\\n                    note = f\\\"Unknown Process: {TSR_PROCESS}\\\"\\n            else:\\n                MODEL = Inventory\\n                tb = \\\"Inventory for Daily Movements.\\\"\\n                search = {\\n                    \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                    \\\"flag_history\\\": False\\n                }\\n                query = MODEL.objects.get(**search) # MODEL.objects.filter(**search)\\n                if True:\\n                    for key, value in row.items():\\n                        if str(value) not in [np.nan, None, \\\"\\\", \\\"NaT\\\"]:\\n                            setattr(query, key, value)\\n                    query.save()\\n                # if query.exists():\\n                #     query = query.first() # Need to Check if there is More than 1.\\n                #     query.update(**row)\\n                    # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                    STATUS = True\\n                    # note = f\\\"Data Updated Successfully in {tb}.\\\"\\n                # else:\\n                #     # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n                #     STATUS = False\\n                #     note = f\\\"Container not found in {tb}.\\\"\\n        except Inventory.MultipleObjectsReturned:\\n            # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n            STATUS = False\\n            note = \\\"Multiple entries found in Inventory. Please contact admin.\\\"\\n            serverPrint(request, note)\\n        except Inventory.DoesNotExist:\\n            # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n            STATUS = False\\n            note = \\\"Container not found in Inventory. Please contact admin.\\\"\\n            serverPrint(request, note)\\n        except Exception as e:\\n            # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n            STATUS = False\\n            note = f\\\"Error: {e} - CONTACT ADMIN.\\\"\\n            serverPrint(request, f\\\"Error: {e} - CONTACT ADMIN.\\\")\\n        # else:\\n        #     query.save()\\n        #     EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n        #     STATUS = True\\n        finally:\\n            if session_id == \\\"*\\\":\\n                # saudi_exe = SaudiExe.objects.get(\\n                #     # CONTAINER_NUMBER=CONTAINER_NUMBER,\\n                #     session_id=row['session_id'],\\n                # )\\n                # EXE_Search_Base = {\\n                #     \\\"session_id\\\": saudi_exe.session_id,\\n                # }\\n                # saudi_exe.flag_completed = True\\n                # saudi_exe.save()\\n                EXE_Search_Base = {\\n                    \\\"session_id\\\": row['session_id'],\\n                }\\n            df.loc[index, 'STATUS'] = STATUS\\n            if STATUS:\\n                EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True, error=False)\\n            else:\\n                EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=False, error=True)\\n            # EXE_Model.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=STATUS, error=not(STATUS))\\n            df.loc[index, 'REMARKS'] = [note] if type(note) != list else note\\n    if session_id != \\\"*\\\":\\n        if saudi_exe.port_choice == \\\"RSGT\\\" and saudi_exe.document_type == \\\"RSGT-UIY_Report\\\":\\n            if EXE_uiy_ReportData.objects.filter(session_id=session_id).exists():\\n                Special_UIY_forVV_DF = reading_as_df_From_ORM(\\n                    Model=EXE_uiy_ReportData,\\n                    condition={\\\"session_id\\\": session_id, 'proccessed': False, 'error': False, \\\"CATEGORY\\\": \\\"TRSHP\\\"},\\n                    ignore_id=True\\n                )\\n                if Special_UIY_forVV_DF.empty and uiy_check:\\n                    messages.error(request, 'No data found | Contact Admin.')\\n                    return redirect('inventory:saudi_exe')\\n                rowz = Special_UIY_forVV_DF.copy().iterrows() # Special_UIY_forVV_DF.copy().to_dict(orient='records')\\n                Special_UIY_forVV_DF['STATUS'] = False\\n                Special_UIY_forVV_DF['REMARKS'] = None\\n                to_combine_df = pd.DataFrame(columns=[\\n                    \\\"CONTAINER_NUMBER\\\", \\\"CONTAINER_SIZE\\\", \\\"CONTAINER_TYPE\\\", \\\"EMPTY_FULL\\\",\\n                    # \\\"ISO_Code\\\", \\n                    \\\"BL_NUMBER\\\", \\\"DISCHARGE_VESSEL_VOY\\\", \\n                    # \\\"TRANSHIPMENT_PORT\\\",\\n                    # \\\"CLIENT_NAME\\\", \\\"LOCATION_NAME\\\", \\\"PRINCIPAL_NAMES\\\",\\n                    \\\"DISCHARGE_DATE\\\", \\\"LOADING_VESSEL_VOY\\\", \\\"SAILING_DATE\\\", \\n                    \\\"STATUS\\\", \\\"REMARKS\\\",\\n                    # \\\"session_id\\\"                \\n                ])\\n                for index, row_copy in rowz:\\n                    CONTAINER_NUMBER = row_copy['CONTAINER_NUMBER']\\n                    row_copy['OUTDATE'] = None\\n                    mapping_dict = NVOCCandLINEdf().set_index('RSGT')['NVOCC'].to_dict()\\n                    try:\\n                        princi = mapping_dict.get(row_copy.get('Line'), row_copy.get('Line'))\\n                    except Exception as e:\\n                        print(f\\\"Mapping error: {e}\\\")\\n                        princi = row_copy.get('Line')\\n                    STATUS = False\\n                    note = None\\n                    try:\\n                        row_copy['INBOUND'] = get_vessel_voyage_from_id(row_copy['INBOUND'])\\n                        if clean_dummy(row_copy['CARRIER_REFERENCE']) is not None:\\n                            crRef = voyage_scrapper.objects.filter(visit_id=clean_dummy(row_copy['CARRIER_REFERENCE'])).order_by('-scrapped_on').first()\\n                            if not crRef:\\n                                row_copy['OUTDATE'] = None\\n                            else:\\n                                if crRef.atd is not None:\\n                                    row_copy['OUTDATE'] = crRef.atd\\n                                else:\\n                                    row_copy['OUTDATE'] = None\\n                        else:\\n                            row_copy['OUTDATE'] = None\\n                        row_copy['CARRIER_REFERENCE'] = get_vessel_voyage_from_id(row_copy['CARRIER_REFERENCE'])\\n                        dataForTranshipment_Container = {\\n                            \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                            \\\"CONTAINER_SIZE\\\": row_copy['SIZE'],\\n                            \\\"CONTAINER_TYPE\\\": row_copy['TYPE'],\\n                            # \\\"BL_NUMBER\\\": row_copy['BL_NUMBER'],\\n                            \\\"EMPTY_FULL\\\": str(row_copy['STATUS']).replace('TRSHP ', ''),\\n                        }\\n                        dataForTranshipment_BL = {\\n                            \\\"BL_NUMBER\\\": row_copy['BL_NUMBER'],\\n                            \\\"ISO_Code\\\": row_copy['ISO'],\\n                            \\\"TRANSHIPMENT_PORT\\\": \\\"JEDDAH\\\",  # because it's RSGT we are processing it as JEDDAH. | NOTE: This is taken from BL.\\n                            \\\"CLIENT_NAME\\\": \\\"GMAC\\\", # NOTE: This is taken from BL.\\n                            \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\", # NOTE: This is taken from BL.\\n                            \\\"PRINCIPAL_NAMES\\\": princi, # NOTE: This is taken from BL.\\n                            \\\"DISCHARGE_VESSEL_VOY\\\": row_copy['INBOUND'],\\n                            \\\"DISCHARGE_DATE\\\": row_copy['INDATE'],\\n                            \\\"LOADING_VESSEL_VOY\\\": row_copy['CARRIER_REFERENCE'],\\n                            \\\"SAILING_DATE\\\": row_copy['OUTDATE'],\\n                            \\\"session_id\\\": session_id,\\n                        }\\n                        if TranshipmentHistory.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER']).exists():\\n                            # NOTE: TODO - Check if Details Match.\\n                            STATUS = False\\n                            note = \\\"Container already found in Transhipment History.\\\"\\n                        elif Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER']).exists():\\n                            ### If Found Update the Details.\\n                            # Create a Transhipment Dict for Keys which dont have None Values, but preserve existing dates if new ones are None\\n                            existing_record = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER']).first()\\n                            dataForTranshipment_BL = {k: v for k, v in dataForTranshipment_BL.items() if k != \\\"DISCHARGE_VESSEL_VOY\\\"}\\n                            # Preserve existing dates if new ones are None/empty\\n                            if dataForTranshipment_BL.get('DISCHARGE_DATE') in [None, '', pd.NaT] and existing_record.DISCHARGE_DATE:\\n                                dataForTranshipment_BL['DISCHARGE_DATE'] = existing_record.DISCHARGE_DATE\\n                            if dataForTranshipment_BL.get('SAILING_DATE') in [None, '', pd.NaT] and existing_record.SAILING_DATE:\\n                                dataForTranshipment_BL['SAILING_DATE'] = existing_record.SAILING_DATE\\n                            Transhipment.objects.filter(BL_NUMBER=row_copy['BL_NUMBER']).update(**{k: v for k, v in dataForTranshipment_BL.items() if v is not None and v != '' and not pd.isna(v)})\\n                            Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER']).update(**{k: v for k, v in dataForTranshipment_Container.items() if v is not None and v != '' and not pd.isna(v)})\\n                            STATUS = True\\n                            note = \\\"Transhipment Data Updated Successfully.\\\"\\n                        elif ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER']).exists():\\n                            dataForTranshipment = {\\n                                **dataForTranshipment_Container,\\n                                **dataForTranshipment_BL,\\n                            }\\n                            ImportBL_Check = ImportsBlTable.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER'])\\n                            PreAlert_Check = PreAlertTracker_Main.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER, BL_NUMBER=row_copy['BL_NUMBER'])\\n                            if ImportBL_Check.exists():\\n                                if PreAlert_Check.exists():\\n                                    first = True\\n                                    for prealert_row in PreAlert_Check:\\n                                        # prealert_row = PreAlert_Check.first()\\n                                        for key, value in {\\n                                            # \\\"CONTAINER_SIZE\\\": prealert_row.CONTAINER_SIZE,\\n                                            # \\\"CONTAINER_TYPE\\\": prealert_row.CONTAINER_TYPE,\\n                                            \\\"POL\\\": prealert_row.IMP_POL,\\n                                            # \\\"TRANSHIPMENT_PORT\\\": prealert_row.IMP_POD,\\n                                            \\\"FPOD\\\": prealert_row.IMP_FPOD,\\n                                            # \\\"BL_NUMBER\\\": prealert_row.BL_NUMBER,\\n                                            \\\"CLIENT_NAME\\\": prealert_row.CLIENT_NAME,\\n                                            \\\"LOCATION_NAME\\\": prealert_row.LOCATION_NAME,\\n                                            \\\"PRINCIPAL_NAMES\\\": prealert_row.PRINCIPAL_NAMES\\n                                        }.items():\\n                                            if key in dataForTranshipment.keys():\\n                                                if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                    dataForTranshipment[key] = value\\n                                        if prealert_row.IMP_VESSEL not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                            dataForTranshipment['DISCHARGE_VESSEL_VOY'] = prealert_row.IMP_VESSEL + \\\"/\\\" + prealert_row.IMP_VOYAGE\\n                                        if first:\\n                                            dataForTranshipment['session_id'] = prealert_row.session_id\\n                                            PreAlertTracker_Old.objects.create(**takeRow2Data(PreAlertTracker_Old, prealert_row)) # PreAlertTracker_Old.objects.create(**prealert_row.__dict__)\\n                                            first = False\\n                                        prealert_row.delete()\\n                                first = True\\n                                for tbl_row in ImportBL_Check:\\n                                    # tbl_row = ImportBL_Check.first()\\n                                    for key, value in {\\n                                        # \\\"CONTAINER_SIZE\\\": tbl_row.CONTAINER_SIZE,\\n                                        # \\\"CONTAINER_TYPE\\\": tbl_row.CONTAINER_TYPE,\\n                                        \\\"POL\\\": tbl_row.IMP_POL,\\n                                        # \\\"TRANSHIPMENT_PORT\\\": tbl_row.IMP_POD,\\n                                        \\\"FPOD\\\": tbl_row.IMP_FPOD,\\n                                        # \\\"BL_NUMBER\\\": tbl_row.BL_NUMBER,\\n                                        \\\"CLIENT_NAME\\\": tbl_row.DELIVERYAGENT_NAME,\\n                                        \\\"LOCATION_NAME\\\": tbl_row.LOCATION_NAME,\\n                                        \\\"PRINCIPAL_NAMES\\\": tbl_row.PRINCIPAL_NAMES\\n                                    }.items():\\n                                        if key in dataForTranshipment.keys():\\n                                            if value != dataForTranshipment[key] and value not in ['', None, np.nan]:\\n                                                dataForTranshipment[key] = value\\n                                    if str(tbl_row.IMP_VSL_VOY).split(\\\"/\\\")[0] not in ['', None, np.nan, \\\"Dummy\\\", \\\" \\\"]:\\n                                        dataForTranshipment['DISCHARGE_VESSEL_VOY'] = tbl_row.IMP_VSL_VOY\\n                                    if first:\\n                                        dataForTranshipment['session_id'] = tbl_row.session_id\\n                                        TBLD_HISTORY.objects.create(**takeRow2Data(TBLD_HISTORY, tbl_row)) # TBLD_HISTORY.objects.create(**tbl_row.__dict__)\\n                                        first = False\\n                                    tbl_row.delete()\\n                                Transhipment.objects.create(**dataForTranshipment)\\n                                STATUS = True\\n                                note = \\\"Transhipment Data Created Successfully from BL Table.\\\"\\n                            else:\\n                                STATUS = False\\n                                note = \\\"Container not found in Transhipment BL Table, Waiting for BL to be Scanned.\\\"\\n                        elif str(row_copy['STATUS']).replace('TRSHP ', '') in ['EMPTY']:\\n                            ### If Empty then Create in TranshipmentCurrent\\n                            dataForEmptyTranshipment = {\\n                                \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                                \\\"CONTAINER_SIZE\\\": row_copy['SIZE'],\\n                                \\\"CONTAINER_TYPE\\\": row_copy['TYPE'],\\n                                \\\"EMPTY_FULL\\\": str(row_copy['STATUS']).replace('TRSHP ', ''),\\n                                \\\"ISO_Code\\\": row_copy['ISO'],\\n                                \\\"BL_NUMBER\\\": row_copy['BL_NUMBER'],\\n                                \\\"DISCHARGE_VESSEL_VOY\\\": row_copy['INBOUND'],\\n                                \\\"TRANSHIPMENT_PORT\\\": \\\"JEDDAH\\\",  # because it's RSGT we are processing it as JEDDAH.\\n                                \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                                \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                                \\\"PRINCIPAL_NAMES\\\": princi,\\n                                \\\"DISCHARGE_DATE\\\": row_copy['INDATE'],\\n                                \\\"LOADING_VESSEL_VOY\\\": row_copy['CARRIER_REFERENCE'],\\n                                \\\"SAILING_DATE\\\": row_copy['OUTDATE'],\\n                                \\\"session_id\\\": session_id,\\n                            }\\n                            STATUS = True\\n                            if Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER).exists():\\n                                existing_transhipment = Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER).first()\\n                                # Preserve existing dates if new ones are None/empty\\n                                if dataForEmptyTranshipment.get('DISCHARGE_DATE') in [None, '', pd.NaT] and existing_transhipment.DISCHARGE_DATE:\\n                                    dataForEmptyTranshipment['DISCHARGE_DATE'] = existing_transhipment.DISCHARGE_DATE\\n                                if dataForEmptyTranshipment.get('SAILING_DATE') in [None, '', pd.NaT] and existing_transhipment.SAILING_DATE:\\n                                    dataForEmptyTranshipment['SAILING_DATE'] = existing_transhipment.SAILING_DATE\\n                                # Only update with non-null values\\n                                update_data = {k: v for k, v in dataForEmptyTranshipment.items() if v is not None and v != '' and not pd.isna(v)}\\n                                Transhipment.objects.filter(CONTAINER_NUMBER=CONTAINER_NUMBER).update(**update_data)\\n                                note = \\\"Transhipment Empty Data Updated Successfully.\\\"\\n                            else:\\n                                Transhipment.objects.create(**dataForEmptyTranshipment)\\n                                note = \\\"Transhipment Empty Data Created Successfully.\\\"\\n                        else:\\n                            STATUS = False\\n                            note = \\\"Container not found in Transhipment or BL Table, Waiting for TSR to be Uploaded.\\\"\\n                    except Exception as e:\\n                        # EXE_uiy_ReportData.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(error=True)\\n                        STATUS = False\\n                        note = f\\\"Error: {e} - CONTACT ADMIN.\\\"\\n                        serverPrint(request, f\\\"Error: {e} - CONTACT ADMIN.\\\")\\n                    # else:\\n                    #     EXE_uiy_ReportData.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True)\\n                    #     STATUS = True\\n                    finally:\\n                        EXE_Search_Base = {\\n                            \\\"session_id\\\": row_copy['session_id'],\\n                        }\\n                        Special_UIY_forVV_DF.loc[index, 'STATUS'] = STATUS\\n                        if STATUS:\\n                            EXE_uiy_ReportData.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=True, error=False)\\n                        else:\\n                            EXE_uiy_ReportData.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=False, error=True)\\n                        # EXE_uiy_ReportData.objects.filter(**{\\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER, **EXE_Search_Base}).update(proccessed=STATUS, error=not(STATUS))\\n                        Special_UIY_forVV_DF.loc[index, 'REMARKS'] = [note] if type(note) != list else note\\n                        to_combine_df = pd.concat([to_combine_df, pd.DataFrame([{\\n                            \\\"CONTAINER_NUMBER\\\": CONTAINER_NUMBER,\\n                            \\\"CONTAINER_SIZE\\\": row_copy['SIZE'],\\n                            \\\"CONTAINER_TYPE\\\": row_copy['TYPE'],\\n                            \\\"EMPTY_FULL\\\": str(row_copy['STATUS']).replace('TRSHP ', ''),\\n                            \\\"ISO_Code\\\": row_copy['ISO'],\\n                            \\\"BL_NUMBER\\\": row_copy['BL_NUMBER'],\\n                            \\\"DISCHARGE_VESSEL_VOY\\\": row_copy['INBOUND'],\\n                            \\\"TRANSHIPMENT_PORT\\\": \\\"JEDDAH\\\",  # because it's RSGT we are processing it as JEDDAH.\\n                            \\\"CLIENT_NAME\\\": \\\"GMAC\\\",\\n                            \\\"LOCATION_NAME\\\": \\\"SAUDI ARABIA\\\",\\n                            \\\"PRINCIPAL_NAMES\\\": princi,\\n                            \\\"DISCHARGE_DATE\\\": row_copy['INDATE'],\\n                            \\\"LOADING_VESSEL_VOY\\\": row_copy['CARRIER_REFERENCE'],\\n                            \\\"SAILING_DATE\\\": row_copy['OUTDATE'],\\n                            # \\\"session_id\\\": session_id,\\n                            \\\"STATUS\\\": STATUS,\\n                            \\\"REMARKS\\\": [note] if type(note) != list else note,\\n                        }])], ignore_index=True)\\n                # Ensure both DataFrames have all columns\\n                all_columns = set(df.columns).union(set(to_combine_df.columns))\\n                for col in all_columns:\\n                    if col not in df.columns:\\n                        df[col] = None\\n                    if col not in to_combine_df.columns:\\n                        to_combine_df[col] = None\\n                # Reorder so STATUS and REMARKS are at the end\\n                ordered_cols = [col for col in all_columns if col not in ['STATUS', 'REMARKS']] + ['STATUS', 'REMARKS']\\n                # Apply column order\\n                df = df[ordered_cols]\\n                to_combine_df = to_combine_df[ordered_cols]\\n                df = pd.concat([df, to_combine_df], ignore_index=True)\\n    # else:\\n    #     pass\\n    df.reset_index(drop=True, inplace=True)\\n    df['STATUS'] = df['STATUS'].apply(lambda x: 'ACCEPT' if x else 'DENY')\\n    uiydrop = []\\n    if 'ISO_Code' in df.columns:\\n        uiydrop.append('ISO_Code')\\n        uiydrop.append('PRINCIPAL_NAMES')\\n        # uiydrop.append('LOADING_VESSEL_VOY')\\n        # uiydrop.append('SAILING_DATE')\\n        uiydrop.append('LOCATION_NAME')\\n        uiydrop.append('TRANSHIPMENT_PORT')\\n        uiydrop.append('CLIENT_NAME')\\n        uiydrop.append('SNTC_DATE')\\n        uiydrop.append('SNTS_DATE')\\n        uiydrop.append('RCVC_DATE')\\n    for dropcol in ['session_id', 'ALT_PORT', 'DETAIL_PROCESS', 'backed_up', 'INVOICE_SESSION_ID', 'INVOICE_PRINCIPAL_NAME'] + uiydrop:\\n        if dropcol in df.columns:\\n            df.drop(columns=dropcol, inplace=True)\\n    if session_id != \\\"*\\\":\\n        saudi_exe.flag_completed = True\\n        saudi_exe.save()\\n    else:\\n        df.sort_values(by='STATUS', ascending=False, inplace=True)\\n    # Make a copy of the dataframe\\n    table_html = df.copy()\\n    # Convert the 'REMARKS' list to an HTML unordered list if it's a non-empty list; otherwise leave it as None\\n    table_html['REMARKS'] = table_html['REMARKS'].apply(\\n        lambda x: \\\"<ul>\\\" + \\\"\\\".join(f\\\"<li>{remark}</li>\\\" for remark in x) + \\\"</ul>\\\" if isinstance(x, list) and x else None\\n    )\\n    # Reset the index so that row.name is a sequential integer\\n    table_html = table_html.reset_index(drop=True)\\n    # Create the modal HTML for each row using the row's index as a unique ID\\n    print(\\\"--=-=--=-================\\\")\\n    def create_modal(row):\\n        x = row['REMARKS']\\n        modal_id = f\\\"staticBackdrop{row.name}\\\"  # Use row.name as the unique identifier\\n        return f\\\"\\\"\\\"\\n            <button type=\\\"button\\\" class=\\\"btn btn-primary\\\" data-bs-toggle=\\\"modal\\\" data-bs-target=\\\"#{modal_id}\\\">\\n                Remarks\\n            </button>\\n            <!-- Modal -->\\n            <div class=\\\"modal fade\\\" id=\\\"{modal_id}\\\" data-bs-backdrop=\\\"static\\\" data-bs-keyboard=\\\"false\\\" tabindex=\\\"-1\\\" aria-labelledby=\\\"staticBackdropLabel\\\" aria-hidden=\\\"true\\\">\\n                <div class=\\\"modal-dialog modal-lg\\\">\\n                    <div class=\\\"modal-content\\\">\\n                        <div class=\\\"modal-header\\\">\\n                            <h5 class=\\\"modal-title\\\" id=\\\"staticBackdropLabel\\\">Remarks</h5>\\n                            <button type=\\\"button\\\" class=\\\"btn-close\\\" data-bs-dismiss=\\\"modal\\\" aria-label=\\\"Close\\\"></button>\\n                        </div>\\n                    <div class=\\\"modal-body\\\" style=\\\"word-wrap: break-word; overflow-wrap: break-word; white-space: normal;\\\">\\n                        {x if x else \\\"No remarks available\\\"}\\n                    </div>\\n                        <div class=\\\"modal-footer\\\">\\n                            <button type=\\\"button\\\" class=\\\"btn btn-secondary\\\" data-bs-dismiss=\\\"modal\\\">Close</button>\\n                        </div>\\n                    </div>\\n                </div>\\n            </div>\\n        \\\"\\\"\\\"\\n    table_html['REMARKS'] = table_html.apply(create_modal, axis=1)\\n    table_html.rename(columns={'REMARKS': 'NOTES'}, inplace=True)\\n    if len(uiydrop) > 0:\\n        column_order = [\\n            'CONTAINER_NUMBER', 'CONTAINER_SIZE', 'CONTAINER_TYPE', 'EMPTY_FULL', \\\"BL_NUMBER\\\",\\n            \\\"DISCHARGE_VESSEL_VOY\\\", 'DISCHARGE_DATE', 'LOADING_VESSEL_VOY', 'SAILING_DATE',\\n            \\\"RCVS_DATE\\\", 'STATUS', 'NOTES'\\n        ]\\n    else:\\n        column_order = table_html.columns.tolist()\\n    # Reorder the columns to match the desired order\\n    table_html = table_html[column_order]\\n    # Convert the DataFrame to HTML with appropriate classes and without escaping HTML\\n    table_html = table_html.to_html(index=False, classes='mytable table table-bordered table-hover shadow-sm', escape=False)\\n    # Create a style block that you can prepend to your HTML\\n    style_block = \\\"\\\"\\\"\\n        <style>\\n            /* Increase the minimum width of header cells and table cells */\\n            .mytable th, .mytable td {\\n                min-width: 160px;   /* Adjust the value as needed */\\n                white-space: nowrap; /* Prevent text wrapping */\\n            }\\n        </style>\\n    \\\"\\\"\\\"\\n    # Prepend the style block to the table HTML\\n    table_html = style_block + table_html\\n    # Optional clean-up replacements\\n    table_html = table_html.replace(r'\\\\n', '')  # Remove newline characters\\n    table_html = table_html.replace('NaT', '')   # Remove NaT values\\n    table_html = table_html.replace('<td>ACCEPT</td>', '<td style=\\\"color: green;\\\">ACCEPT</td>')\\n    table_html = table_html.replace('<td>DENY</td>', '<td style=\\\"color: red;\\\">DENY</td>')\\n    # Save the modified dataframe to a CSV file\\n    if 'REMARKS' in df.columns:\\n        df.drop(columns='REMARKS', inplace=True)\\n    file_name = \\\"TSR_REPORT\\\" if TSR else \\\"DAILY_REPORT\\\"\\n    csv_path = os.path.join(BASE_DIR, 'uploads', f'{file_name}_processed_sheet.csv')\\n    df.to_csv(csv_path, index=False)\\n    # Render the table and provide a download link\\n    return render(request, 'process_sheet.html', {\\n        'table_html': table_html,\\n        'file_name': f'{file_name}_processed_sheet.csv',\\n        'redirect_url': reverse('inventory:saudi_exe'),\\n    })\",\n",
      "  \"start_line\": 585,\n",
      "  \"end_line\": 1563,\n",
      "  \"function\": \"process_exe_data\",\n",
      "  \"file\": \"C:\\\\Users\\\\JonathanChackoPattas\\\\OneDrive - Maritime Support Solutions\\\\Desktop\\\\MSS-Automation\\\\Inventory\\\\views_pack\\\\terminal.py\",\n",
      "  \"helpers\": [\n",
      "    \"CommonModule.funcCenter.addedOnValue\",\n",
      "    \"Connectors.db_con.move_inventory\",\n",
      "    \"Connectors.db_con.reading_as_df_From_ORM\",\n",
      "    \"Inventory.EXE_Extras.Terminal_Common.NVOCCandLINEdf\",\n",
      "    \"Inventory.views_pack.terminal.clean_dummy\",\n",
      "    \"Inventory.views_pack.terminal.get_error_session_ids\",\n",
      "    \"Inventory.views_pack.terminal.get_vessel_voyage_from_id\",\n",
      "    \"Marine.jcpLogger.serverPrint\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "path, func = create_file_path(BASE_PATH, Function_Path)\n",
    "print(path, \"\\n\"+func+\"()\")\n",
    "# out = extract_function_source_ast(\n",
    "#     file_path=path,\n",
    "#     func_or_qualname=func,\n",
    "#     include_helpers=True,\n",
    "#     base_path=BASE_PATH,\n",
    "#     detailed_functions=True,\n",
    "#     reursive_helper=True,\n",
    "# )\n",
    "out = extract_function_source(\n",
    "    params=ParameterInputSchema(\n",
    "        function_path=Function_Path,\n",
    "        include_helpers=True,\n",
    "        base_path=BASE_PATH,\n",
    "        detailed_functions=False,\n",
    "        recursive_helper=False,\n",
    "    )\n",
    ")\n",
    "import json\n",
    "print(json.dumps(out, indent=2))\n",
    "# for key, value in out.items():\n",
    "#     print(f\"\\n{key}:\")\n",
    "#     print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107ce54",
   "metadata": {},
   "source": [
    "# Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75af12c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef91645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def to_function_path(base_path: str, file_path: str, func_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Reverse of create_file_path: return 'module.submodule.function' from a file path and function name.\n",
    "    - Handles package __init__.py (maps to the package name, not '...__init__').\n",
    "    - Ensures file_path is under base_path (avoids external libraries).\n",
    "    \"\"\"\n",
    "    base = Path(base_path).resolve()\n",
    "    file = Path(file_path).resolve()\n",
    "\n",
    "    # Ensure it's inside your project root\n",
    "    try:\n",
    "        rel = file.relative_to(base)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"{file} is outside BASE_PATH {base}\")\n",
    "\n",
    "    if rel.suffix != \".py\":\n",
    "        raise ValueError(\"file_path must be a .py file\")\n",
    "\n",
    "    rel_no_ext = rel.with_suffix(\"\")\n",
    "    parts = list(rel_no_ext.parts)\n",
    "\n",
    "    # If pointing at a package __init__.py, drop the final '__init__'\n",
    "    if parts and parts[-1] == \"__init__\":\n",
    "        parts = parts[:-1]\n",
    "\n",
    "    module = \".\".join(parts).strip(\".\")\n",
    "    if not module:\n",
    "        raise ValueError(\"Could not derive module name from the given path.\")\n",
    "\n",
    "    return f\"{module}.{func_name}\"\n",
    "\n",
    "Function_Path = to_function_path(BASE_PATH, path, func)\n",
    "print(Function_Path)  # Inventory.views_pack.terminal.process_exe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_function_extractor.py\n",
    "from __future__ import annotations\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List, Union\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        # Fallback for very old Python: try ast.get_source_segment\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        # Best-effort end line calc\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "\n",
    "def _called_top_level_functions(fn: FuncNode) -> List[str]:\n",
    "    \"\"\"Naive: collect ast.Name() calls used by this function.\"\"\"\n",
    "    called: set[str] = set()\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call) and isinstance(n.func, ast.Name):\n",
    "            called.add(n.func.id)\n",
    "    return sorted(called)\n",
    "\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "    - func_or_qualname: \"foo\" or \"ClassName.method\"\n",
    "    - include_helpers=True: also append any same-file top-level helper functions\n",
    "      that are directly called by the target (naive name-based detection).\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        # also allow class methods lookup by qualname if provided differently\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    # ambiguous unless qualname given; pick first match\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "    helper_function_paths = []\n",
    "    if include_helpers and not class_name:\n",
    "        called = _called_top_level_functions(target_node)\n",
    "        helpers = [name for name in called if name in top_funcs and name != func_name]\n",
    "        for h in helpers:\n",
    "            # h_code, hs, he = _slice_with_decorators(src_lines, top_funcs[h])\n",
    "            # pieces.append(f\"\\n# Helper '{h}' from {path.name}:{hs}-{he}\\n{h_code}\")\n",
    "            helper_function_paths.append(to_function_path(BASE_PATH, file_path, h))\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "        \"helpers\": helper_function_paths,\n",
    "    }\n",
    "\n",
    "print(extract_function_source_ast(path, func, include_helpers=True)) # ['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a303c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_function_extractor.py\n",
    "from __future__ import annotations\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List, Union\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        # Fallback for very old Python: try ast.get_source_segment\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        # Best-effort end line calc\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "\n",
    "def _called_top_level_functions(fn: FuncNode) -> List[str]:\n",
    "    \"\"\"Naive: collect ast.Name() calls used by this function.\"\"\"\n",
    "    called: set[str] = set()\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call) and isinstance(n.func, ast.Name):\n",
    "            called.add(n.func.id)\n",
    "    return sorted(called)\n",
    "\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "    - func_or_qualname: \"foo\" or \"ClassName.method\"\n",
    "    - include_helpers=True: also append any same-file top-level helper functions\n",
    "      that are directly called by the target (naive name-based detection).\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        # also allow class methods lookup by qualname if provided differently\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    # ambiguous unless qualname given; pick first match\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "\n",
    "    if include_helpers and not class_name:\n",
    "        called = _called_top_level_functions(target_node)\n",
    "        helpers = [name for name in called if name in top_funcs and name != func_name]\n",
    "        for h in helpers:\n",
    "            h_code, hs, he = _slice_with_decorators(src_lines, top_funcs[h])\n",
    "            pieces.append(f\"\\n# Helper '{h}' from {path.name}:{hs}-{he}\\n{h_code}\")\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = extract_function_source_ast(path, func) # , include_helpers=True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd10394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libcst_function_extractor.py\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import libcst as cst\n",
    "from libcst import FunctionDef, ClassDef\n",
    "from libcst.metadata import MetadataWrapper, ParentNodeProvider, PositionProvider\n",
    "\n",
    "def extract_function_source_libcst(file_path: str | Path, func_or_qualname: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the exact function/method source with original formatting preserved.\n",
    "    Supports:\n",
    "      - \"foo\" (top-level)\n",
    "      - \"ClassName.method\" (class method)\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    module = cst.parse_module(src)\n",
    "    wrapper = MetadataWrapper(module)\n",
    "    pos = wrapper.resolve(PositionProvider)\n",
    "    parent = wrapper.resolve(ParentNodeProvider)\n",
    "\n",
    "    class_name = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    matches: list[FunctionDef] = []\n",
    "\n",
    "    class Finder(cst.CSTVisitor):\n",
    "        METADATA_DEPENDENCIES = (ParentNodeProvider, PositionProvider)\n",
    "\n",
    "        def visit_FunctionDef(self, node: FunctionDef) -> None:\n",
    "            if node.name.value != func_name:\n",
    "                return\n",
    "            p = parent[node]\n",
    "            if class_name:\n",
    "                if isinstance(p, ClassDef) and p.name.value == class_name:\n",
    "                    matches.append(node)\n",
    "            else:\n",
    "                # top-level if parent is Module\n",
    "                from libcst import Module\n",
    "                if isinstance(p, Module):\n",
    "                    matches.append(node)\n",
    "\n",
    "    wrapper.visit(Finder())\n",
    "\n",
    "    if not matches:\n",
    "        # Build a list of available names for a helpful error\n",
    "        available: list[str] = []\n",
    "        class Collector(cst.CSTVisitor):\n",
    "            METADATA_DEPENDENCIES = (ParentNodeProvider,)\n",
    "            def visit_FunctionDef(self, node: FunctionDef) -> None:\n",
    "                p = parent[node]\n",
    "                if isinstance(p, cst.Module):\n",
    "                    available.append(node.name.value)\n",
    "                elif isinstance(p, ClassDef):\n",
    "                    available.append(f\"{p.name.value}.{node.name.value}\")\n",
    "\n",
    "        wrapper.visit(Collector())\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {sorted(available)}\")\n",
    "\n",
    "    node = matches[0]  # pick first match if multiple\n",
    "    code = module.code_for_node(node)\n",
    "    r = pos[node]  # CodeRange(start=(line, col), end=(line, col))\n",
    "\n",
    "    return {\n",
    "        \"code\": code,\n",
    "        \"start_line\": r.start.line,\n",
    "        \"end_line\": r.end.line,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(extract_function_source_libcst(path, func)[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ecb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_index_extractor.py\n",
    "try:\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "    from llama_index.core.node_parser import CodeSplitter\n",
    "except ImportError:\n",
    "    from llama_index import SimpleDirectoryReader\n",
    "    from llama_index.node_parser import CodeSplitter\n",
    "\n",
    "# Load a single Python file as a \"document\"\n",
    "docs = SimpleDirectoryReader(input_files=[Path(path)]).load_data()\n",
    "\n",
    "# Split by lines with overlap (keeps function/class blocks coherent)\n",
    "splitter = CodeSplitter(\n",
    "    language=\"python\",\n",
    "    chunk_lines=60,\n",
    "    chunk_lines_overlap=10,\n",
    "    max_chars=2000,\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(docs)\n",
    "\n",
    "print(f\"Total chunks: {len(nodes)}\")\n",
    "for i, n in enumerate(nodes, 1):\n",
    "    meta = getattr(n, \"metadata\", {}) or {}\n",
    "    start = meta.get(\"start_line\") or meta.get(\"start\") or \"?\"\n",
    "    end = meta.get(\"end_line\") or meta.get(\"end\") or \"?\"\n",
    "    print(f\"\\n--- Chunk {i} [{start}-{end}] ---\")\n",
    "    print(n.text[:400])  # preview first 400 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5832592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_recursive_extractor.py\n",
    "try:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "except ImportError:\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "python_text = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "py = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "chunks = py.split_text(python_text)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "for i, ch in enumerate(chunks[:5], 1):  # preview first 5\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(ch[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bfdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_python_extractor.py\n",
    "try:\n",
    "    from langchain_text_splitters import PythonCodeTextSplitter\n",
    "except ImportError:\n",
    "    from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "python_code = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "splitter = PythonCodeTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(python_code)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "for i, ch in enumerate(chunks[:10], 1):  # preview first 10 small chunks\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(ch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
