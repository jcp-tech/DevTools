{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50884d42",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6687368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JonathanChackoPattas\\OneDrive - Maritime Support Solutions\\Desktop\\MSS-Automation\\Inventory\\views_pack\\terminal.py \n",
      "saudi_tsr_output_checker()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "Function_Path = \"Inventory.views_pack.terminal.saudi_tsr_output_checker\" # Inventory.views_pack.terminal.process_exe_data\n",
    "BASE_PATH = r\"C:\\Users\\JonathanChackoPattas\\OneDrive - Maritime Support Solutions\\Desktop\\MSS-Automation\"\n",
    "def create_file_path(base_path, function_path):\n",
    "    function_parts = function_path.split(\".\")\n",
    "    function_name = function_parts[-1]  # last part is the function\n",
    "    module_parts = function_parts[:-1]  # everything before is the module path\n",
    "    for part in module_parts:\n",
    "        base_path = os.path.join(base_path, part)\n",
    "    return base_path + \".py\", function_name\n",
    "path, func = create_file_path(BASE_PATH, Function_Path)\n",
    "print(path, \"\\n\"+func+\"()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e7a7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from typing import Optional, Dict, Tuple, List, Union, Iterable, Set\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "# -----------------------------\n",
    "# project indexing\n",
    "# -----------------------------\n",
    "\n",
    "_EXCLUDE_DIRS = {\n",
    "    \".git\", \"__pycache__\", \".mypy_cache\", \".pytest_cache\", \".ruff_cache\",\n",
    "    \"build\", \"dist\", \"site-packages\", \"venv\", \".venv\", \"env\", \".env\",\n",
    "    \".idea\", \".vscode\", \"node_modules\", \".tox\", \".eggs\",\n",
    "    \"venv-windows\", \"venv-linux\",\n",
    "}\n",
    "\n",
    "def _iter_py_files(root: Path) -> Iterable[Path]:\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        # prune excluded dirs in-place for speed\n",
    "        dirnames[:] = [d for d in dirnames if d not in _EXCLUDE_DIRS]\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".py\"):\n",
    "                yield Path(dirpath) / f\n",
    "\n",
    "def _to_module_qualname(base_path: Path, file_path: Path) -> str:\n",
    "    rel = file_path.relative_to(base_path)\n",
    "    if rel.name == \"__init__.py\":\n",
    "        rel = rel.parent\n",
    "    else:\n",
    "        rel = rel.with_suffix(\"\")\n",
    "    return \".\".join(rel.parts)\n",
    "\n",
    "def _to_function_path(base_path: Path, file_path: Path, func_name: str) -> str:\n",
    "    mod = _to_module_qualname(base_path, file_path)\n",
    "    return f\"{mod}.{func_name}\" if mod else func_name\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "@lru_cache(maxsize=4)\n",
    "def _index_project_functions(base_path_str: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        by_name: Dict[str, List[tuple[Path, str /*module*/, FuncNode]]]\n",
    "        by_mod_func: Dict[str /*module.func*/, tuple[Path, FuncNode]]\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path_str).resolve()\n",
    "    by_name: Dict[str, List[Tuple[Path, str, FuncNode]]] = {}\n",
    "    by_mod_func: Dict[str, Tuple[Path, FuncNode]] = {}\n",
    "\n",
    "    for py in _iter_py_files(base_path):\n",
    "        try:\n",
    "            src = py.read_text(encoding=\"utf-8\")\n",
    "            mod = ast.parse(src)\n",
    "        except Exception:\n",
    "            continue  # skip unreadable / syntactically invalid files\n",
    "\n",
    "        top_funcs, _ = _gather_defs(mod)\n",
    "        module_name = _to_module_qualname(base_path, py)\n",
    "        for name, node in top_funcs.items():\n",
    "            by_name.setdefault(name, []).append((py, module_name, node))\n",
    "            by_mod_func[f\"{module_name}.{name}\"] = (py, node)\n",
    "\n",
    "    return by_name, by_mod_func\n",
    "\n",
    "# -----------------------------\n",
    "# source slicing & calls\n",
    "# -----------------------------\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "def _get_attr_chain(node: ast.AST) -> Tuple[Optional[str], List[str]]:\n",
    "    \"\"\"\n",
    "    For something like pkg.sub.mod.helper, return (\"pkg\", [\"sub\", \"mod\", \"helper\"]).\n",
    "    If not an attribute chain rooted at Name, return (None, []).\n",
    "    \"\"\"\n",
    "    chain: List[str] = []\n",
    "    cur = node\n",
    "    root_name = None\n",
    "    while isinstance(cur, ast.Attribute):\n",
    "        chain.append(cur.attr)\n",
    "        cur = cur.value\n",
    "    if isinstance(cur, ast.Name):\n",
    "        root_name = cur.id\n",
    "        chain.reverse()\n",
    "        return root_name, chain\n",
    "    return None, []\n",
    "\n",
    "def _collect_calls_and_locals(fn: FuncNode) -> tuple[set[str], list[tuple[str, list[str]]], set[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      bare: names of bare calls like {'helper', 'slugify'}\n",
    "      attrs: qualified calls like [('utils', ['slugify']), ('pkg', ['sub', 'do'])]\n",
    "      bound_locals: names bound in the function (params, assignments, etc.)\n",
    "    \"\"\"\n",
    "    bare: Set[str] = set()\n",
    "    attrs: List[Tuple[str, List[str]]] = []\n",
    "    bound_locals: Set[str] = set()\n",
    "\n",
    "    # params\n",
    "    args = fn.args\n",
    "    for a in getattr(args, \"posonlyargs\", []): bound_locals.add(a.arg)\n",
    "    for a in args.args: bound_locals.add(a.arg)\n",
    "    if args.vararg: bound_locals.add(args.vararg.arg)\n",
    "    for a in args.kwonlyargs: bound_locals.add(a.arg)\n",
    "    if args.kwarg: bound_locals.add(args.kwarg.arg)\n",
    "\n",
    "    def add_targets(t):\n",
    "        if isinstance(t, ast.Name):\n",
    "            bound_locals.add(t.id)\n",
    "        elif isinstance(t, (ast.Tuple, ast.List)):\n",
    "            for elt in t.elts:\n",
    "                add_targets(elt)\n",
    "\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call):\n",
    "            if isinstance(n.func, ast.Name):\n",
    "                bare.add(n.func.id)\n",
    "            else:\n",
    "                root, chain = _get_attr_chain(n.func)\n",
    "                if root and chain:\n",
    "                    attrs.append((root, chain))\n",
    "        elif isinstance(n, ast.Assign):\n",
    "            for t in n.targets: add_targets(t)\n",
    "        elif isinstance(n, ast.AnnAssign) and n.target:\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.AugAssign):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.For):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.With):\n",
    "            for item in n.items:\n",
    "                if item.optional_vars: add_targets(item.optional_vars)\n",
    "        elif isinstance(n, ast.comprehension):\n",
    "            add_targets(n.target)\n",
    "        elif isinstance(n, ast.ExceptHandler) and n.name:\n",
    "            bound_locals.add(n.name)\n",
    "\n",
    "    return bare, attrs, bound_locals\n",
    "\n",
    "# -----------------------------\n",
    "# import resolution\n",
    "# -----------------------------\n",
    "\n",
    "def _resolve_relative_module(this_module: str, level: int, module: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Resolve relative 'from ... import ...' to absolute dotted module.\n",
    "    this_module: e.g., 'Inventory.views_pack.terminal'\n",
    "    level: 1 => from . import x  (parent)\n",
    "    level: 2 => from ..pkg import y\n",
    "    \"\"\"\n",
    "    pkg_parts = this_module.split(\".\")[:-1]  # package of the file\n",
    "    if level > len(pkg_parts) + 1:\n",
    "        return None\n",
    "    base = pkg_parts[: len(pkg_parts) - (level - 1)]\n",
    "    if module:\n",
    "        base += module.split(\".\")\n",
    "    return \".\".join(p for p in base if p)\n",
    "\n",
    "def _parse_import_maps(mod: ast.Module, this_module: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      import_aliases: dict of local name -> absolute module dotted path\n",
    "         e.g., {'utils': 'Inventory.utils', 'mod': 'Inventory.x.y'}\n",
    "      from_names: dict of local imported symbol -> absolute module or module.symbol\n",
    "         e.g., {'slugify': 'Inventory.utils.slugify', 'utils': 'Inventory.utils'}\n",
    "    \"\"\"\n",
    "    import_aliases: Dict[str, str] = {}\n",
    "    from_names: Dict[str, str] = {}\n",
    "\n",
    "    for n in mod.body:\n",
    "        if isinstance(n, ast.Import):\n",
    "            for a in n.names:\n",
    "                full = a.name  # 'pkg' or 'pkg.sub.mod'\n",
    "                local = a.asname if a.asname else full.split(\".\")[0]\n",
    "                import_aliases[local] = full\n",
    "        elif isinstance(n, ast.ImportFrom):\n",
    "            if n.level and n.level > 0:\n",
    "                base_mod = _resolve_relative_module(this_module, n.level, n.module)\n",
    "            else:\n",
    "                base_mod = n.module\n",
    "            if not base_mod:\n",
    "                continue\n",
    "            for a in n.names:\n",
    "                local = a.asname if a.asname else a.name\n",
    "                # Could be a submodule or a symbol; we store as fully qualified\n",
    "                from_names[local] = f\"{base_mod}.{a.name}\"\n",
    "    return import_aliases, from_names\n",
    "\n",
    "# -----------------------------\n",
    "# main API\n",
    "# -----------------------------\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    "    *,\n",
    "    base_path: str | Path,\n",
    "    aggressive_fallback: bool = False,  # set True to allow cross-project name fallback\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "\n",
    "    Args:\n",
    "      file_path: Path to the file containing the target function/method.\n",
    "      func_or_qualname: \"foo\" or \"ClassName.method\".\n",
    "      include_helpers: If True, also return helper function *paths* discovered\n",
    "                       from calls inside the target, searching across the project.\n",
    "      base_path: Project root directory. Only files under this root are considered.\n",
    "      aggressive_fallback: If True, when we can't prove a binding, include all\n",
    "                           same-named top-level functions found across the project.\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        \"code\": str,\n",
    "        \"start_line\": int,\n",
    "        \"end_line\": int,\n",
    "        \"function\": str,\n",
    "        \"file\": str,\n",
    "        \"helpers\": List[str]  # dotted function paths across the project\n",
    "      }\n",
    "    \"\"\"\n",
    "    base = Path(base_path).resolve()\n",
    "    path = Path(file_path).resolve()\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "\n",
    "    helper_function_paths: List[str] = []\n",
    "    if include_helpers:\n",
    "        by_name, by_mod_func = _index_project_functions(str(base))\n",
    "\n",
    "        this_module = _to_module_qualname(base, path)\n",
    "        import_aliases, from_names = _parse_import_maps(mod, this_module)\n",
    "\n",
    "        # collect calls + bound locals in the function\n",
    "        bare_names, qual_calls, bound_locals = _collect_calls_and_locals(target_node)\n",
    "\n",
    "        resolved_funcs: set[str] = set()\n",
    "\n",
    "        # ---- Bare calls: helper() ----\n",
    "        for name in bare_names:\n",
    "            # If the name is locally bound (param/assignment/etc.), we can't safely resolve it.\n",
    "            if name in bound_locals:\n",
    "                continue\n",
    "\n",
    "            # Same-file top-level function wins\n",
    "            if name in top_funcs:\n",
    "                resolved_funcs.add(f\"{this_module}.{name}\")\n",
    "                continue\n",
    "\n",
    "            # from pkg.mod import name [as alias]\n",
    "            if name in from_names:\n",
    "                full = from_names[name]  # e.g., 'pkg.mod.helper'\n",
    "                if full in by_mod_func:\n",
    "                    resolved_funcs.add(full)\n",
    "                    continue\n",
    "\n",
    "            # No project-wide name scan unless explicitly allowed\n",
    "            if aggressive_fallback:\n",
    "                for _fp, module_name, _node in by_name.get(name, []):\n",
    "                    # skip the exact same target function identity\n",
    "                    if module_name == this_module and name == func_name:\n",
    "                        continue\n",
    "                    resolved_funcs.add(f\"{module_name}.{name}\")\n",
    "\n",
    "        # ---- Qualified calls: utils.helper(), pkg.sub.mod.helper() ----\n",
    "        for root, chain in qual_calls:\n",
    "            if not chain:\n",
    "                continue\n",
    "\n",
    "            # If root is locally bound, treat as object, not module\n",
    "            if root in bound_locals:\n",
    "                continue\n",
    "\n",
    "            func = chain[-1]\n",
    "            prefix = chain[:-1]\n",
    "\n",
    "            # Root can come from either 'import ... as root' OR 'from ... import root as root'\n",
    "            base_mod = import_aliases.get(root)\n",
    "            if not base_mod:\n",
    "                # If root was imported via 'from X import root', that map points to X.root\n",
    "                maybe = from_names.get(root)\n",
    "                if maybe:\n",
    "                    # If 'root' is actually a submodule imported via 'from X import root'\n",
    "                    base_mod = maybe\n",
    "\n",
    "            if not base_mod:\n",
    "                continue  # unknown root â†’ skip\n",
    "\n",
    "            full_mod = \".\".join([base_mod] + prefix) if prefix else base_mod\n",
    "            candidate = f\"{full_mod}.{func}\"\n",
    "\n",
    "            if candidate in by_mod_func:\n",
    "                resolved_funcs.add(candidate)\n",
    "            elif aggressive_fallback:\n",
    "                for _fp, module_name, _node in by_name.get(func, []):\n",
    "                    resolved_funcs.add(f\"{module_name}.{func}\")\n",
    "\n",
    "        helper_function_paths = sorted(resolved_funcs)\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "        \"helpers\": helper_function_paths,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1d07c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "code:\n",
      "# Extracted from terminal.py:455-583\n",
      "@csrf_exempt\n",
      "def saudi_tsr_output_checker(request):\n",
      "    if request.method == 'POST':\n",
      "        try:\n",
      "            report = request.POST.get('document_type')\n",
      "            file_path = request.FILES.get('file')\n",
      "            if not file_path:\n",
      "                return JsonResponse({\"status\": \"error\", \"message\": \"No file uploaded.\", \"data\": pd.DataFrame().to_dict()}, status=400)\n",
      "            TSR = True\n",
      "            if False:\n",
      "                pass\n",
      "            ## DAMMAM DEPOTS\n",
      "            elif report == \"GLOBE-DAMMAM_Report\":\n",
      "                df = GLOBE_DAMMAM(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER','RCVC_DATE', 'SNTS_DATE']\n",
      "                \"\"\"\n",
      "            elif report == \"ALI-RAZA_Report\":\n",
      "                df = ALI_RAZA_DAMMAM(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER','RCVC_DATE', 'SNTS_DATE']\n",
      "                \"\"\"\n",
      "            ## JEDDAH DEPOTS\n",
      "            elif report == \"GLOBE-JEDDAH_Report\":\n",
      "                df = GLOBE_JEDDAH(file_path)\n",
      "                \"\"\"\n",
      "                returns \n",
      "                    ['CONTAINER_NUMBER', 'SNTC_DATE'] for .txt files \n",
      "                    OR\n",
      "                    ['CONTAINER_NUMBER','RCVC_DATE', 'SNTS_DATE'] for .xlsx files\n",
      "                \"\"\"\n",
      "            elif report == \"BAHRI-JEDDAH_Report\": # NOTE\n",
      "                df = BAHRI_JEDDAH(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER','RCVC_DATE', 'SNTS_DATE']\n",
      "                \"\"\"\n",
      "            elif report == \"VISION-JEDDAH_Report\": # TODO\n",
      "                df = VISION_JEDDAH(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER','RCVC_DATE', 'SNTS_DATE']\n",
      "                \"\"\"\n",
      "            ## DAMMAM TERMINALS\n",
      "            elif report == \"SGP_Report\":\n",
      "                df = SGP_TSR_Main(\n",
      "                    path=file_path,\n",
      "                    # tsr_dict=TSR_DICT\n",
      "                )\n",
      "                \"\"\"\n",
      "                returns ['LINE', 'BL_NUMBER', 'CONTAINER_NUMBER', 'CONTAINER_SIZE', 'EMPTY_FULL', 'PORT', 'CONTAINER_TYPE', 'PROCESS']\n",
      "                \"\"\"\n",
      "                df['LINE'] = df['LINE'].map(NVOCCandLINEdf().set_index('SGP-DMM')['NVOCC'].to_dict())\n",
      "            ## JEDDAH TERMINALS\n",
      "            elif report == \"RSGT-TSR_Report\":\n",
      "                df = RSGT_TSR_Main(\n",
      "                    path=file_path,\n",
      "                    # tsr_dict=TSR_DICT\n",
      "                )\n",
      "                \"\"\"\n",
      "                returns ['LINE', 'BL_NUMBER', 'CONTAINER_NUMBER', 'CONTAINER_SIZE', 'EMPTY_FULL', 'PORT', 'CONTAINER_TYPE', 'PROCESS']\n",
      "                \"\"\"\n",
      "                df['LINE'] = df['LINE'].map(NVOCCandLINEdf().set_index('RSGT')['NVOCC'].to_dict())\n",
      "            elif report == \"DPW_Report\":\n",
      "                df, error, message = DPW_TSR_Main(\n",
      "                    path=file_path,\n",
      "                    # tsr_dict=TSR_DICT\n",
      "                )\n",
      "                \"\"\"\n",
      "                returns ['LINE', 'BL_NUMBER', 'CONTAINER_NUMBER', 'CONTAINER_SIZE', 'EMPTY_FULL', 'PORT', 'CONTAINER_TYPE', 'PROCESS'], error, message\n",
      "                \"\"\"\n",
      "                if error:\n",
      "                    return JsonResponse({\"status\": \"error\", \"message\": message}, status=400)\n",
      "                # else:\n",
      "                #     pass\n",
      "                df['LINE'] = df['LINE'].map(NVOCCandLINEdf().set_index('SCT/DP WORLD')['NVOCC'].to_dict())\n",
      "            # elif report == \"MandM_Report\":\n",
      "            #     df = MandM_TSR_Main(\n",
      "            #         path=file_path,\n",
      "            #         tsr_dict=TSR_DICT\n",
      "            #     )\n",
      "            ## OTHER REPORTS\n",
      "            elif report == \"RSGT-DAILY_Report\":\n",
      "                df = RSGT_Daily(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER','SNTC_DATE','RCVS_DATE']\n",
      "                \"\"\"\n",
      "            elif report == \"RSGT-UIY_Report\":\n",
      "                df, Special_UIY_forVV_DF = RSGT_UnitInYard(file_path)\n",
      "                \"\"\"\n",
      "                returns ['CONTAINER_NUMBER', 'RCVS_DATE'], ['CONTAINER_NUMBER', 'ISO', 'SIZE', 'TYPE', 'STATUS', 'CARRIER_REFERENCE', 'INBOUND', 'INDATE', 'POD', 'BL_NUMBER', 'CATEGORY', 'LINE']\n",
      "                \"\"\"\n",
      "            # elif report == \"Common_Report\":\n",
      "            #     df = Common_Report()\n",
      "            #     \"\"\"\n",
      "            #     returns ['CONTAINER_NUMBER', 'SNTC_DATE', 'RCVC_DATE', 'SNTS_DATE', 'RCVS_DATE']\n",
      "            #     \"\"\"\n",
      "            # ## SCRAPPERS\n",
      "            # elif report in [\"SGP_Scrapper\", \"DPW_Scrapper\"]:\n",
      "            #     obj = ScrappersMain()\n",
      "            #     if report == \"SGP_Scrapper\":\n",
      "            #         df = SecondaryData(\n",
      "            #             df=obj.START(SITE=\"SGP_Services_Saudi\"), \n",
      "            #             session_id=session_id\n",
      "            #         )\n",
      "            #     elif report == \"DPW_Scrapper\":\n",
      "            #         df = SecondaryData(\n",
      "            #             df=obj.START(SITE=\"DP_World_Saudi\"), \n",
      "            #             session_id=session_id\n",
      "            #         )\n",
      "            else:\n",
      "                df = pd.DataFrame(columns=['CONTAINER_NUMBER', 'SNTC_DATE', 'RCVC_DATE', 'SNTS_DATE', 'RCVS_DATE']) if not TSR else pd.DataFrame()\n",
      "            if df.empty:\n",
      "                return JsonResponse({\"status\": \"error\", \"message\": \"No data found in the file.\", \"data\": df.to_dict()}, status=400)\n",
      "            else:\n",
      "                rows = []\n",
      "                for row in df.to_dict(orient='records'):\n",
      "                    for keys in row.keys():\n",
      "                        if row[keys] in [np.nan, None, \"\"]:\n",
      "                            row[keys] = None\n",
      "                        elif str(row[keys]) == \"NaT\":\n",
      "                            row[keys] = None\n",
      "                        # else:\n",
      "                        #     pass\n",
      "                    rows.append(row)\n",
      "                df = pd.DataFrame(rows)\n",
      "                return JsonResponse({\"status\": \"success\", \"message\": \"Data processed successfully.\", \"data\": df.to_dict()}, status=200)\n",
      "        except Exception as e:\n",
      "            serverPrint(request, e)\n",
      "            return JsonResponse({\"status\": \"error\", \"message\": str(e), \"data\": pd.DataFrame().to_dict()}, status=500)\n",
      "    return JsonResponse({\"status\": \"error\", \"message\": \"Invalid request method.\", \"data\": pd.DataFrame().to_dict()}, status=400)\n",
      "\n",
      "start_line:\n",
      "455\n",
      "\n",
      "end_line:\n",
      "583\n",
      "\n",
      "function:\n",
      "saudi_tsr_output_checker\n",
      "\n",
      "file:\n",
      "C:\\Users\\JonathanChackoPattas\\OneDrive - Maritime Support Solutions\\Desktop\\MSS-Automation\\Inventory\\views_pack\\terminal.py\n",
      "\n",
      "helpers:\n",
      "['Inventory.EXE_Extras.DepotModule.ALI_RAZA_DAMMAM', 'Inventory.EXE_Extras.DepotModule.BAHRI_JEDDAH', 'Inventory.EXE_Extras.DepotModule.GLOBE_DAMMAM', 'Inventory.EXE_Extras.DepotModule.GLOBE_JEDDAH', 'Inventory.EXE_Extras.DepotModule.VISION_JEDDAH', 'Inventory.EXE_Extras.TerminalModule.RSGT_Daily', 'Inventory.EXE_Extras.TerminalModule.RSGT_UnitInYard', 'Inventory.EXE_Extras.Terminal_Common.NVOCCandLINEdf', 'Inventory.EXE_Extras.Terminal_Main.DPW_TSR_Main', 'Inventory.EXE_Extras.Terminal_Main.RSGT_TSR_Main', 'Inventory.EXE_Extras.Terminal_Main.SGP_TSR_Main', 'Marine.jcpLogger.serverPrint']\n"
     ]
    }
   ],
   "source": [
    "out = extract_function_source_ast(\n",
    "    file_path=path,\n",
    "    func_or_qualname=func,\n",
    "    include_helpers=True,\n",
    "    base_path=BASE_PATH,\n",
    ")\n",
    "# import json\n",
    "# print(json.dumps(out, indent=2))\n",
    "for key, value in out.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107ce54",
   "metadata": {},
   "source": [
    "# Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d75af12c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef91645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def to_function_path(base_path: str, file_path: str, func_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Reverse of create_file_path: return 'module.submodule.function' from a file path and function name.\n",
    "    - Handles package __init__.py (maps to the package name, not '...__init__').\n",
    "    - Ensures file_path is under base_path (avoids external libraries).\n",
    "    \"\"\"\n",
    "    base = Path(base_path).resolve()\n",
    "    file = Path(file_path).resolve()\n",
    "\n",
    "    # Ensure it's inside your project root\n",
    "    try:\n",
    "        rel = file.relative_to(base)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"{file} is outside BASE_PATH {base}\")\n",
    "\n",
    "    if rel.suffix != \".py\":\n",
    "        raise ValueError(\"file_path must be a .py file\")\n",
    "\n",
    "    rel_no_ext = rel.with_suffix(\"\")\n",
    "    parts = list(rel_no_ext.parts)\n",
    "\n",
    "    # If pointing at a package __init__.py, drop the final '__init__'\n",
    "    if parts and parts[-1] == \"__init__\":\n",
    "        parts = parts[:-1]\n",
    "\n",
    "    module = \".\".join(parts).strip(\".\")\n",
    "    if not module:\n",
    "        raise ValueError(\"Could not derive module name from the given path.\")\n",
    "\n",
    "    return f\"{module}.{func_name}\"\n",
    "\n",
    "Function_Path = to_function_path(BASE_PATH, path, func)\n",
    "print(Function_Path)  # Inventory.views_pack.terminal.process_exe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_function_extractor.py\n",
    "from __future__ import annotations\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List, Union\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        # Fallback for very old Python: try ast.get_source_segment\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        # Best-effort end line calc\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "\n",
    "def _called_top_level_functions(fn: FuncNode) -> List[str]:\n",
    "    \"\"\"Naive: collect ast.Name() calls used by this function.\"\"\"\n",
    "    called: set[str] = set()\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call) and isinstance(n.func, ast.Name):\n",
    "            called.add(n.func.id)\n",
    "    return sorted(called)\n",
    "\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "    - func_or_qualname: \"foo\" or \"ClassName.method\"\n",
    "    - include_helpers=True: also append any same-file top-level helper functions\n",
    "      that are directly called by the target (naive name-based detection).\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        # also allow class methods lookup by qualname if provided differently\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    # ambiguous unless qualname given; pick first match\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "    helper_function_paths = []\n",
    "    if include_helpers and not class_name:\n",
    "        called = _called_top_level_functions(target_node)\n",
    "        helpers = [name for name in called if name in top_funcs and name != func_name]\n",
    "        for h in helpers:\n",
    "            # h_code, hs, he = _slice_with_decorators(src_lines, top_funcs[h])\n",
    "            # pieces.append(f\"\\n# Helper '{h}' from {path.name}:{hs}-{he}\\n{h_code}\")\n",
    "            helper_function_paths.append(to_function_path(BASE_PATH, file_path, h))\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "        \"helpers\": helper_function_paths,\n",
    "    }\n",
    "\n",
    "print(extract_function_source_ast(path, func, include_helpers=True)) # ['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a303c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast_function_extractor.py\n",
    "from __future__ import annotations\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple, List, Union\n",
    "\n",
    "FuncNode = Union[ast.FunctionDef, ast.AsyncFunctionDef]\n",
    "\n",
    "def _gather_defs(module: ast.Module) -> Tuple[Dict[str, FuncNode], Dict[str, Dict[str, FuncNode]]]:\n",
    "    \"\"\"Return (top_level_funcs, class_methods[class_name][func_name]).\"\"\"\n",
    "    top_level_funcs: Dict[str, FuncNode] = {}\n",
    "    class_methods: Dict[str, Dict[str, FuncNode]] = {}\n",
    "\n",
    "    for node in module.body:\n",
    "        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "            top_level_funcs[node.name] = node\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            methods: Dict[str, FuncNode] = {}\n",
    "            for b in node.body:\n",
    "                if isinstance(b, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                    methods[b.name] = b\n",
    "            class_methods[node.name] = methods\n",
    "    return top_level_funcs, class_methods\n",
    "\n",
    "\n",
    "def _slice_with_decorators(src_lines: List[str], fn: FuncNode) -> Tuple[str, int, int]:\n",
    "    \"\"\"Return (code, start_line, end_line), 1-based line numbers inclusive.\"\"\"\n",
    "    start = fn.lineno\n",
    "    if getattr(fn, \"decorator_list\", None):\n",
    "        start = min(getattr(dec, \"lineno\", start) for dec in fn.decorator_list) or start\n",
    "    end = getattr(fn, \"end_lineno\", None)\n",
    "    if end is None:\n",
    "        # Fallback for very old Python: try ast.get_source_segment\n",
    "        full_src = \"\".join(src_lines)\n",
    "        seg = ast.get_source_segment(full_src, fn)\n",
    "        if seg is None:\n",
    "            raise RuntimeError(\"Unable to determine function end; please use Python 3.8+.\")\n",
    "        # Best-effort end line calc\n",
    "        end = start + seg.count(\"\\n\")\n",
    "        return seg, start, end\n",
    "    return \"\\n\".join(src_lines[start - 1 : end]), start, end\n",
    "\n",
    "\n",
    "def _called_top_level_functions(fn: FuncNode) -> List[str]:\n",
    "    \"\"\"Naive: collect ast.Name() calls used by this function.\"\"\"\n",
    "    called: set[str] = set()\n",
    "    for n in ast.walk(fn):\n",
    "        if isinstance(n, ast.Call) and isinstance(n.func, ast.Name):\n",
    "            called.add(n.func.id)\n",
    "    return sorted(called)\n",
    "\n",
    "\n",
    "def extract_function_source_ast(\n",
    "    file_path: str | Path,\n",
    "    func_or_qualname: str,\n",
    "    include_helpers: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract a function or method source by name.\n",
    "    - func_or_qualname: \"foo\" or \"ClassName.method\"\n",
    "    - include_helpers=True: also append any same-file top-level helper functions\n",
    "      that are directly called by the target (naive name-based detection).\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    src_lines = src.splitlines()\n",
    "\n",
    "    mod = ast.parse(src)\n",
    "    top_funcs, class_methods = _gather_defs(mod)\n",
    "\n",
    "    class_name: Optional[str] = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    target_node: Optional[FuncNode] = None\n",
    "    if class_name:\n",
    "        methods = class_methods.get(class_name, {})\n",
    "        target_node = methods.get(func_name)\n",
    "    else:\n",
    "        target_node = top_funcs.get(func_name)\n",
    "        # also allow class methods lookup by qualname if provided differently\n",
    "        if target_node is None:\n",
    "            for cls, methods in class_methods.items():\n",
    "                if func_name in methods:\n",
    "                    # ambiguous unless qualname given; pick first match\n",
    "                    target_node = methods[func_name]\n",
    "                    class_name = cls\n",
    "                    break\n",
    "\n",
    "    if target_node is None:\n",
    "        available = sorted(list(top_funcs.keys()) + [f\"{c}.{m}\" for c, ms in class_methods.items() for m in ms])\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {available}\")\n",
    "\n",
    "    main_code, start, end = _slice_with_decorators(src_lines, target_node)\n",
    "    pieces = [f\"# Extracted from {path.name}:{start}-{end}\\n{main_code}\"]\n",
    "\n",
    "    if include_helpers and not class_name:\n",
    "        called = _called_top_level_functions(target_node)\n",
    "        helpers = [name for name in called if name in top_funcs and name != func_name]\n",
    "        for h in helpers:\n",
    "            h_code, hs, he = _slice_with_decorators(src_lines, top_funcs[h])\n",
    "            pieces.append(f\"\\n# Helper '{h}' from {path.name}:{hs}-{he}\\n{h_code}\")\n",
    "\n",
    "    return {\n",
    "        \"code\": \"\\n\".join(pieces),\n",
    "        \"start_line\": start,\n",
    "        \"end_line\": end,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = extract_function_source_ast(path, func) # , include_helpers=True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd10394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libcst_function_extractor.py\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import libcst as cst\n",
    "from libcst import FunctionDef, ClassDef\n",
    "from libcst.metadata import MetadataWrapper, ParentNodeProvider, PositionProvider\n",
    "\n",
    "def extract_function_source_libcst(file_path: str | Path, func_or_qualname: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the exact function/method source with original formatting preserved.\n",
    "    Supports:\n",
    "      - \"foo\" (top-level)\n",
    "      - \"ClassName.method\" (class method)\n",
    "    Returns: {\"code\": str, \"start_line\": int, \"end_line\": int, \"function\": str, \"file\": str}\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    src = path.read_text(encoding=\"utf-8\")\n",
    "    module = cst.parse_module(src)\n",
    "    wrapper = MetadataWrapper(module)\n",
    "    pos = wrapper.resolve(PositionProvider)\n",
    "    parent = wrapper.resolve(ParentNodeProvider)\n",
    "\n",
    "    class_name = None\n",
    "    func_name = func_or_qualname\n",
    "    if \".\" in func_or_qualname:\n",
    "        class_name, func_name = func_or_qualname.split(\".\", 1)\n",
    "\n",
    "    matches: list[FunctionDef] = []\n",
    "\n",
    "    class Finder(cst.CSTVisitor):\n",
    "        METADATA_DEPENDENCIES = (ParentNodeProvider, PositionProvider)\n",
    "\n",
    "        def visit_FunctionDef(self, node: FunctionDef) -> None:\n",
    "            if node.name.value != func_name:\n",
    "                return\n",
    "            p = parent[node]\n",
    "            if class_name:\n",
    "                if isinstance(p, ClassDef) and p.name.value == class_name:\n",
    "                    matches.append(node)\n",
    "            else:\n",
    "                # top-level if parent is Module\n",
    "                from libcst import Module\n",
    "                if isinstance(p, Module):\n",
    "                    matches.append(node)\n",
    "\n",
    "    wrapper.visit(Finder())\n",
    "\n",
    "    if not matches:\n",
    "        # Build a list of available names for a helpful error\n",
    "        available: list[str] = []\n",
    "        class Collector(cst.CSTVisitor):\n",
    "            METADATA_DEPENDENCIES = (ParentNodeProvider,)\n",
    "            def visit_FunctionDef(self, node: FunctionDef) -> None:\n",
    "                p = parent[node]\n",
    "                if isinstance(p, cst.Module):\n",
    "                    available.append(node.name.value)\n",
    "                elif isinstance(p, ClassDef):\n",
    "                    available.append(f\"{p.name.value}.{node.name.value}\")\n",
    "\n",
    "        wrapper.visit(Collector())\n",
    "        raise ValueError(f\"Function '{func_or_qualname}' not found. Available: {sorted(available)}\")\n",
    "\n",
    "    node = matches[0]  # pick first match if multiple\n",
    "    code = module.code_for_node(node)\n",
    "    r = pos[node]  # CodeRange(start=(line, col), end=(line, col))\n",
    "\n",
    "    return {\n",
    "        \"code\": code,\n",
    "        \"start_line\": r.start.line,\n",
    "        \"end_line\": r.end.line,\n",
    "        \"function\": func_or_qualname,\n",
    "        \"file\": str(path),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(extract_function_source_libcst(path, func)[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ecb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama_index_extractor.py\n",
    "try:\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "    from llama_index.core.node_parser import CodeSplitter\n",
    "except ImportError:\n",
    "    from llama_index import SimpleDirectoryReader\n",
    "    from llama_index.node_parser import CodeSplitter\n",
    "\n",
    "# Load a single Python file as a \"document\"\n",
    "docs = SimpleDirectoryReader(input_files=[Path(path)]).load_data()\n",
    "\n",
    "# Split by lines with overlap (keeps function/class blocks coherent)\n",
    "splitter = CodeSplitter(\n",
    "    language=\"python\",\n",
    "    chunk_lines=60,\n",
    "    chunk_lines_overlap=10,\n",
    "    max_chars=2000,\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(docs)\n",
    "\n",
    "print(f\"Total chunks: {len(nodes)}\")\n",
    "for i, n in enumerate(nodes, 1):\n",
    "    meta = getattr(n, \"metadata\", {}) or {}\n",
    "    start = meta.get(\"start_line\") or meta.get(\"start\") or \"?\"\n",
    "    end = meta.get(\"end_line\") or meta.get(\"end\") or \"?\"\n",
    "    print(f\"\\n--- Chunk {i} [{start}-{end}] ---\")\n",
    "    print(n.text[:400])  # preview first 400 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5832592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_recursive_extractor.py\n",
    "try:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "except ImportError:\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "python_text = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "py = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "chunks = py.split_text(python_text)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "for i, ch in enumerate(chunks[:5], 1):  # preview first 5\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(ch[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bfdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_python_extractor.py\n",
    "try:\n",
    "    from langchain_text_splitters import PythonCodeTextSplitter\n",
    "except ImportError:\n",
    "    from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "python_code = Path(path).read_text(encoding=\"utf-8\")\n",
    "\n",
    "splitter = PythonCodeTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(python_code)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "for i, ch in enumerate(chunks[:10], 1):  # preview first 10 small chunks\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(ch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
